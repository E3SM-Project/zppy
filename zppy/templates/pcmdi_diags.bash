#!/bin/bash
{% include 'slurm_header.sh' %}

{{ environment_commands }}

# Turn on debug output if needed
debug={{ debug }}
if [[ "${debug,,}" == "true" ]]; then
  set -x
fi

# Need this setup as otherwise can not generate diagnostics
export UCX_SHM_DEVICES=all # or not set UCX_NET_DEVICES at all

# Make sure UVCDAT doesn't prompt us about anonymous logging
export UVCDAT_ANONYMOUS_LOG=False

# Script dir
cd {{ scriptDir }}

# Get jobid
id=${SLURM_JOBID}

# Update status file
STARTTIME=$(date +%s)
echo "RUNNING ${id}" > {{ prefix }}.status

# Basic definitions
case="{{ case }}"
www="{{ www }}"
y1={{ year1 }}
y2={{ year2 }}
Y1="{{ '%04d' % (year1) }}"
Y2="{{ '%04d' % (year2) }}"
{% if run_type == "model_vs_model" %}
ref_Y1="{{ '%04d' % (ref_year1) }}"
ref_Y2="{{ '%04d' % (ref_year2) }}"
{%- endif %}
run_type="{{ run_type }}"
tag="{{ tag }}"

results_dir=${tag}_${Y1}-${Y2}

ref_name={{ ref_name }}

#info for pcmdi specific data structure
case_id=v$(date '+%Y%m%d')

# Create temporary workdir
workdir=`mktemp -d tmp.${id}.XXXX`
cd ${workdir}

# Create results directory
if [ ! -d ${results_dir} ];then
  mkdir -p ${results_dir}
fi
#directory to save land/sea mask generated by pcmdi
fixed_dir="${results_dir}/fixed"
if [ ! -d ${fixed_dir} ];then
  mkdir -p ${fixed_dir}
fi

# Prepare data files for pcmdi diagnostics, which is achieved by two steps:
# (a) convert e3sm output to cmip type, which used the "e3sm_to_cmip" function
#     available at zppy (modifications are made to process more variables and
#     3D fileds at fixed pressure levels).
# (b) locate observations in e3sm diagnostics and convert them to the pcmdi preferred
#     data format
#file to specify reference data used to derive the diagnostic metrics
cat > reference_alias.json << EOF
{% include reference_alias %}
EOF
#regions specified to derive global/regional mean metrics
cat > regions_specs.json << EOF
{% include regions_specs %}
EOF
#file include derived variables
cat > derived_variable.json << EOF
{% include derived_variable %}
EOF
#file to genereate land/sea mask data if not available
cat > process_sftlf.py << EOF
{% include process_sftlf %}
EOF

{%- if ("mean_climate" in sets) %}
#file to genereate figures for mean climate metrics(temporary)
cat > mean_climate_plot_parser.py << EOF
{% include clim_plot_parser %}
EOF
#file to genereate figures for mean climate metrics(temporary)
cat > mean_climate_plot_driver.py << EOF
{% include clim_plot_driver %}
EOF
{%- endif %}

# script for pcmdi pre-processing
cat > collect_data.py << EOF
import os
import subprocess
import time
import psutil
import json
import sys
import glob
import collections
import cdms2
import gc
import numpy as np
from re import split
from itertools import chain
from shutil import copyfile
from subprocess import Popen, PIPE, call

def childCount():
    current_process = psutil.Process()
    children = current_process.children()
    return(len(children))

def combine_time_series(variables, start_yr, end_yr, num_years,
                        cmip_name, dir_source, out_dic_file, outpath,
                        multiprocessing, num_workers):
  #special case treatment (variables not in cmip cmor list)
  altmod_dic = {"sst"    : "ts",
                "taux"   : "tauu",
                "tauy"   : "tauv",
                "rstcre" : "SWCF",
                "rltcre" : "LWCF"}
  # list of model data dictionary
  var_list = []; lstcm0 = []; lstcm1 = []
  mod_out = collections.OrderedDict()
  for key in variables:
    if "_" in key or "-" in key:
      var = split("_|-", key)[0]
    else:
      var = key
    varin = var
    if var in ["areacella", "sftlf", "orog"]:
      fpaths = sorted(glob.glob(os.path.join(dir_source,var+"_*.nc")))
      for fpath in fpaths:
        if os.path.exists(fpath):
          output = os.path.join(outpath,"{}_fx_{}.nc".format(var,product))
          copyfile(fpath,output)
      del(fpaths)
    else:
      fpaths = sorted(glob.glob(os.path.join(dir_source,varin+"_*.nc")))
      #########################################################################################
      #code below attempts to address special scenarios
      if len(fpaths) < 1 and var in altmod_dic.keys():
        varin = altmod_dic.get(var,var)
        if varin == "SWCF" or varin == "LWCF":
          dir_source1 = "/".join(dir_source.split("/")[0:-2])+"/ts/monthly/{{ts_num_years}}yr"
          fpaths = sorted(glob.glob(os.path.join(dir_source1,varin+"_*.nc")))
        else:
          fpaths = sorted(glob.glob(os.path.join(dir_source,varin+"_*.nc")))
      #########################################################################################
      if len(fpaths) > 0:
        tableId = fpaths[0].split("/")[-1].split("_")[1]
        if tableId not in [ "Amon", "Lmon", "Omon", "SImon" ]:
           tableId = "Amon"
        yms = '{:04d}01'.format(start_yr)
        yme = '{:04d}12'.format(end_yr)
        fname = "{}.{}.{}.{}.{}.{}.{}-{}.nc".format(
		    cmip_name.split(".")[0],
                    cmip_name.split(".")[1],
                    cmip_name.split(".")[2].replace(".","-"),
                    cmip_name.split(".")[3],
                    tableId,var,yms,yme)
        output = os.path.join(outpath,fname)
        if (var not in var_list) or (not os.path.exists(output)):
          var_list.append(var)
          cmd_list = []
          cmd_list.append("ncrcat -v {} -d time,{}-01-01,{}-12-31".format(varin,yms[0:4],yme[0:4]))
          for fpath in fpaths:
            cmd_list.append(fpath)
          cmd_list.append(output)
          cdm0 = (" ".join(cmd_list))
          lstcm0.append(cdm0)
          del(cmd_list,cdm0)
          if varin != var:
            cmd_extra = "ncrename -v {},{} {}".format(varin,var,output)
            lstcm1.append(cmd_extra)
            del(cmd_extra)
          ############################################################
          #record the test model data information
          mod_out[var] = { "mip"        : cmip_name.split(".")[0],
                           "exp"        : cmip_name.split(".")[1],
			   "model"      : cmip_name.split(".")[2].replace(".","-"),
                           "realization": cmip_name.split(".")[3],
                           "tableId"    : tableId,
                           "file_path"  : output,
                           "template"   : fname,
                           "start_yymm" : yms,
                           "end_yymm"   : yme,
                           "varin"      : varin }
        del(tableId,yms,yme,fname,output)
      del(fpaths)
    del(var,varin)
    gc.collect()
  # Save test model data information required for next step
  json.dump(mod_out,
            open(out_dic_file, "w"),
            sort_keys=True,
            indent=4,
            separators=(",", ": "))
  del(mod_out,variables,altmod_dic)

  #finally process the data in parallel
  if not os.path.exists(outpath):
    os.makedirs(outpath,mode=0o777)
  lstall = list(chain(lstcm0,lstcm1))
  lensub = [len(lstcm0),len(lstcm1)]
  lensub = np.cumsum(lensub) - 1
  print("Number of jobs starting is ", str(len(lstall)))
  procs = []
  for i,p in enumerate(lstall):
    print('running %s' % (str(p)))
    proc = Popen(p, stdout=PIPE, shell=True)
    if multiprocessing == True:
      procs.append(proc)
      while (childCount() > num_workers):
        time.sleep(0.25)
        [pp.communicate() for pp in procs] # this will get the exit code
        procs = []
      else:
        if (i == len(lstall)-1):
          try:
            outs, errs = proc.communicate()
            if proc.returncode == 0:
              print("stdout = {}; stderr = {}".format(str(outs),str(errs)))
            else:
              exit("ERROR: subprocess {} failed".format(str(lstall[i])))
          except:
            break
    else:
      return_code = proc.communicate()
      if return_code != 0:
        exit("Failed to run {}".format(str(p)))
  del(lstall,lensub,lstcm0,lstcm1)

  #set a delay to esure all process fully done
  time.sleep(1)
  print("done submitting")

  if len(var_list) > 0:
    print("# of variables available for diagnostics: ", len(var_list))
  else:
    exit("ERROR: can not found model variables to process....")

  return var_list

def locate_ts_observation (variables, obs_sets, start_yr, end_yr,
                           input_path, out_dic_file, outpath,
                           multiprocessing, num_workers):
  # fixed observational name convention to be consistent with cmip
  mip = "obs"; realization = "00"; tableId = "Amon"
  # special case treatment (these obs vars are inconsistent with cmor vars)
  altobs_dic = { "pr"      : "PRECT",
                 "sst"     : "ts",
                 "sfcWind" : "si10",
                 "taux"    : "tauu",
                 "tauy"    : "tauv",
                 "rltcre"  : "toa_cre_lw_mon",
                 "rstcre"  : "toa_cre_sw_mon",
                 "rtmt"    : "toa_net_all_mon"}

  # find and process observational data avaiable in e3sm_diags
  var_list = []; lstcm0  = []; lstcm1  = []
  obs_dic = json.load(open(os.path.join('.','reference_alias.json')))
  obs_out = collections.OrderedDict()
  for i,key in enumerate(variables):
    if "_" in key or "-" in key:
      var = key.split("_|-", var)[0]
    else:
      var = key
    if len(obs_sets) != len(variables):
      option = obs_sets[0]
    else:
      option = obs_sets[i]
    if "default" in obs_sets or "alternate" in obs_sets:
      obstag = obs_dic[var][option]
    else:
      inv_map = {v: k for k, v in obs_dic[var].items()}
      if len(obs_sets) != len(variables):
        obstag = obs_sets[0]
      else:
        obstag = obs_sets[i]
      option = inv_map[obstag]
      del(inv_map)
    varin = var
    if "ceres_ebaf" in obstag:
      fpaths = sorted(glob.glob(os.path.join(input_path,
                      obstag.replace('ceres_ebaf','ceres_ebaf*'),
                      varin+"_*.nc")))
      if len(fpaths) < 1 and var in altobs_dic.keys():
        varin = altobs_dic.get(var,var)
        fpaths = sorted(glob.glob(os.path.join(input_path,
                      obstag.replace('ceres_ebaf','ceres_ebaf*'),
                      varin+"_*.nc")))
    else:
      fpaths = sorted(glob.glob(os.path.join(input_path,obstag,var+"_*.nc")))
      if len(fpaths) < 1 and var in altobs_dic.keys():
        varin = altobs_dic.get(var,var)
        fpaths = sorted(glob.glob(os.path.join(input_path,obstag,varin+"_*.nc")))

    if len(fpaths) > 0 and os.path.exists(fpaths[0]):
      template = fpaths[0].split("/")[-1]
      obsname = fpaths[0].split("/")[-2]
      fyms = template.split("_")[-2][0:6]
      fyme = template.split("_")[-1][0:6]
      yms = '{:04d}{:02d}'.format(start_yr,1)
      yme = '{:04d}{:02d}'.format(end_yr,12)
      if int(yms) < int(fyms):
        yms = fyms
      if int(yme) > int(fyme):
        yme = fyme

      #rename file following cmip-like convention
      fname = "{}.{}.{}.{}.{}.{}.{}-{}.nc".format(
               mip,option,obsname.replace(".","-"),realization,tableId,var,yms,yme)
      output = os.path.join(outpath,fname)
      if (var not in var_list) or (not os.path.exists(output)):
        var_list.append(var)
        cmd = "ncrcat -v {} -d time,{}-01-01,{}-12-31 {} {}".format(
                       varin,yms[0:4],yme[0:4],fpaths[0],output)
        lstcm0.append(cmd); del(cmd)
        if var != varin:
          cmd_extra = "ncrename -v {},{} {}".format(varin,var,output)
          lstcm1.append(cmd_extra)
          del(cmd_extra)

        #record the observation information
        obs_out[var] = { "mip"         : mip,
                         "exp"         : option,
                         "realization" : realization,
                         "tableId"     : tableId,
                         "model"       : obsname,
                         "file_path"   : output,
                         "template"    : fname,
                         "start_yymm"  : yms,
                         "end_yymm"    : yme,
                         "varin"       : varin}
      del(template,obsname,fyms,fyme,yms,yme,fname,output)
    else :
      print("warning: reference data not found for", var)
    del(var,varin,option,obstag)
    gc.collect()

  # Save observational information required for next step
  json.dump(obs_out,
            open(out_dic_file,"w"),
            sort_keys=True,
            indent=4,
            separators=(",", ": "))
  del(obs_dic,obs_out,obs_sets,altobs_dic)

  #finally process the data in parallel
  if not os.path.exists(outpath):
    os.makedirs(outpath,mode=0o777)
  lstall = list(chain(lstcm0,lstcm1))
  lensub = [len(lstcm0),len(lstcm1)]
  lensub = np.cumsum(lensub) - 1
  print("Number of jobs starting is ", str(len(lstall)))
  procs = []
  for i,p in enumerate(lstall):
    print('running %s' % (str(p)))
    proc = Popen(p, stdout=PIPE, shell=True)
    if multiprocessing == True:
      procs.append(proc)
      while (childCount() > num_workers):
        time.sleep(0.25)
        [pp.communicate() for pp in procs] # this will get the exit code
        procs = []
      else:
        if (i == len(lstall)-1):
          try:
            outs, errs = proc.communicate()
            if proc.returncode == 0:
              print("stdout = {}; stderr = {}".format(str(outs),str(errs)))
            else:
              exit("ERROR: subprocess {} failed".format(str(lstall[i])))
          except:
            break
    else:
      return_code = proc.communicate()
      if return_code != 0:
        exit("Failed to run {}".format(str(p)))
  del(lstall,lensub,lstcm0,lstcm1)

  #set a delay to avoid delay in writing process
  time.sleep(1)
  print("done submitting")

  if len(var_list) > 0:
    print("# of variables in observations: ", len(var_list))
  else:
    exit("ERROR: can not found model variables to process....")

  return var_list

def main():
  #basic information
  start_yr = int('${Y1}')
  end_yr = int('${Y2}')
  num_years = end_yr - start_yr + 1

  multiprocessing = {{multiprocessing}}
  num_workers = {{num_workers}}

  # Model
  # Test data directory
{% if run_type == "model_vs_obs" %}
  test_data_dir = 'ts'
{% elif run_type == "model_vs_model" %}
  test_data_dir = 'ts_test'
{%- endif %}
  test_name = '${case}'
  test_start_yr = start_yr
  test_end_yr = end_yr
  test_dir_source='{{ output }}/post/atm/{{ grid }}/cmip_ts/monthly'

  #info for pcmdi data structure
  test_cmip_name = '{{cmip_name}}'

  #Ref
{% if run_type == "model_vs_obs" %}
  # Obs
  reference_dir_source = '{{ obs_ts }}'
  ref_data_dir = 'ts_ref'
  ref_start_yr = {{ ref_start_yr }}
  ref_end_yr = ref_start_yr + num_years - 1
  if (ref_end_yr <= {{ ref_final_yr }}):
    ref_end_yr = ref_end_yr
  else:
    ref_end_yr = {{ ref_final_yr }}
{% elif run_type == "model_vs_model" %}
  # Reference
  reference_dir_source = '{{ reference_data_path_ts }}'
  ref_data_dir = 'ts_ref'
  ref_name = '${ref_name}'
  short_ref_name = '{{ short_ref_name }}'
  ref_start_yr = {{ ref_start_yr }}
  ref_end_yr = {{ ref_final_yr }}
  #info for pcmdi data structure
  ref_cmip_name = '{{ cmip_name_ref }}'

  # Optionally, swap test and reference model
  if {{ swap_test_ref }}:
    test_data_dir, ref_data_dir = ref_data_dir, test_data_dir
    test_name, ref_name = ref_name, test_name
    short_test_name, short_ref_name = short_ref_name, short_test_name
    ref_cmip_name, test_cmip_name = test_cmip_name, ref_cmip_name
{%- endif %}

  ################################################################
  # process test model data for comparision
  ################################################################
  # variable list in configuration file #
  variables = list("{{ vars }}".split(","))
  print("process test model data for comparision")
  test_dic_file = os.path.join("${results_dir}",'{}_{{sub}}_mon_catalogue.json'.format(test_data_dir))
  cmor_vars = combine_time_series(variables,test_start_yr,test_end_yr,
                                  int({{ts_num_years}}),test_cmip_name,
                                  test_dir_source,test_dic_file,test_data_dir,
				  multiprocessing,num_workers)
  ################################################################
  # process reference data for comparison
  ################################################################
  print("process reference obs/model data for comparision")
{% if run_type == "model_vs_obs" %}
  obs_sets = list('{{ obs_sets }}'.split(","))
  refr_dic_file = os.path.join("${results_dir}",'{}_{{sub}}_mon_catalogue.json'.format(ref_data_dir))
  refr_vars = locate_ts_observation(cmor_vars,obs_sets,
                                    ref_start_yr,ref_end_yr,
                                    reference_dir_source,
                                    refr_dic_file,ref_data_dir,
                                    multiprocessing,num_workers)

  print("# of variables in test model: ", len(cmor_vars))
  print("# of variables in reference model: ", len(refr_vars))
  del(refr_vars,cmor_vars)
{% elif run_type == "model_vs_model" %}
  refr_dic_file = os.path.join("${results_dir}",'{}_{{sub}}_mon_catalogue.json'.format(ref_data_dir))
  refr_vars = combine_time_series(cmor_vars,ref_start_yr,ref_end_yr,
                                  int({{ts_num_years_ref}}),ref_cmip_name,
                                  ref_dir_source,refr_dic_file,ref_data_dir,
                                  multiprocessing,num_workers)

  print("# of variables in test model: ", len(cmor_vars))
  print("# of variables in reference model: ", len(refr_vars))
  del(refr_vars,cmor_vars)
{%- endif %}

if __name__ == "__main__":
  main()

EOF

################################
# Pcmdi pre-processing to link
# required data to work directory
command="python -u collect_data.py"
time ${command}
if [ $? != 0 ]; then
  cd {{ scriptDir }}
  echo 'ERROR (9)' > {{ prefix }}.status
  exit 9
fi

################################################################
# generate input parameter for pcmdi metrics driver
{%- if ("mean_climate" in sets) or ("variability_mode" in sets) or ("enso" in sets) %}
cat > parameterfile.py << EOF
import os
import sys
import json

#basic information
start_yr = int('${Y1}')
end_yr = int('${Y2}')
num_years = end_yr - start_yr + 1

# Model
# Test data path
{% if run_type == "model_vs_obs" %}
test_data_dir = 'ts'
{% elif run_type == "model_vs_model" %}
test_data_dir = 'ts_test'
{%- endif %}
test_name = '${case}'
test_start_yr = start_yr
test_end_yr = end_yr
test_dir_source='{{ output }}/post/atm/{{ grid }}/cmip_ts/monthly'
test_cmip_name = '{{ cmip_name }}'

# Ref
{% if run_type == "model_vs_obs" %}
# Obs
reference_dir_source = '{{ obs_ts }}'
ref_data_dir = 'ts_ref'
ref_start_yr = {{ ref_start_yr }}
ref_end_yr = ref_start_yr + num_years - 1
if (ref_end_yr <= {{ ref_final_yr }}):
  ref_end_yr = ref_end_yr
else:
  ref_end_yr = {{ ref_final_yr }}
{% elif run_type == "model_vs_model" %}
# Reference
reference_dir_source = '{{ reference_data_path_ts }}'
ref_data_dir = 'ts_ref'
ref_name = '${ref_name}'
short_ref_name = '{{ short_ref_name }}'
ref_start_yr = {{ ref_start_yr }}
ref_end_yr = {{ ref_final_yr }}
ref_cmip_name = '{{ cmip_name_ref }}'

# Optionally, swap test and reference model
if {{ swap_test_ref }}:
  test_data_dir, ref_data_dir = ref_data_dir, test_data_dir
  test_name, ref_name = ref_name, test_name
  short_test_name, short_ref_name = short_ref_name, short_test_name
  ref_cmip_name, test_cmip_name = test_cmip_name, ref_cmip_name
{%- endif %}

# shared options
case_id = "${case_id}"

# Record NetCDF output
nc_out_obs = {{ nc_out_obs }}
nc_out = {{ nc_out }}
if nc_out:
  ext = ".nc"
else:
  ext = ".xml"

user_notes = 'Provenance and results'
parallel = False
debug = {{ pmp_debug }}

# Generate plots
plot = {{ plot }}
plot_obs = {{ plot_obs }} # optional

# Additional settings
run_type = '{{ run_type }}'
figure_format = '{{ figure_format }}'

{%- if "mean_climate" in subset %}
#############################################################
#parameter setup specific for mean climate metrics
#############################################################
mip = test_cmip_name.split(".")[0]
exp = test_cmip_name.split(".")[1]
product = test_cmip_name.split(".")[2]
realm = test_cmip_name.split(".")[3]
realization = realm

{% if run_type == "model_vs_obs" %}
test_data_set = [ test_cmip_name.split(".")[2] ]
{% elif run_type == "model_vs_model" %}
test_data_set = [ test_cmip_name.split(".")[2], ref_cmip_name.split(".")[2] ]
{%- endif %}

modver = "${case_id}"

# Generate CMEC compliant json
cmec = {{ cmec }}

# SIMULATION PARAMETER
period = "{:04d}{:02d}-{:04d}{:02d}".format(test_start_yr,1,test_end_yr,12)

# INTERPOLATION OPTIONS
target_grid = '{{ target_grid }}'  # OPTIONS: '2.5x2.5' or an actual cdms2 grid object
targetGrid = target_grid
target_grid_string = '{{ target_grid_string }}'
regrid_tool = '{{ regrid_tool }}' # OPTIONS: 'regrid2','esmf'
regrid_method = '{{ regrid_method }}' # OPTIONS: 'linear','conservative', only if tool is esmf
regrid_tool_ocn = '{{ regrid_tool_ocn }}' # OPTIONS: "regrid2","esmf"
regrid_method_ocn = ( '{{ regrid_method_ocn }}' )  # OPTIONS: 'linear','conservative', only if tool is esmf

# SAVE INTERPOLATED MODEL CLIMATOLOGIES ?
save_test_clims = {{ save_test_clims }}

# CUSTOMIZE REGIONS VALUES NAMES
regions_values = {"land":100.,"ocean":0.}

#defined regions
regions_specs = json.load(open(os.path.join(".",'regions_specs.json')))
for kk in regions_specs.keys():
  if "domain" in regions_specs[kk].keys():
    if "latitude" in regions_specs[kk]['domain'].keys():
      regions_specs[kk]['domain']['latitude'] = tuple(regions_specs[kk]['domain']['latitude'])
    if "longitude" in regions_specs[kk]['domain'].keys():
      regions_specs[kk]['domain']['longitude'] = tuple(regions_specs[kk]['domain']['longitude'])

#region specified for each variable
regions =json.load(open(os.path.join("${results_dir}",'var_region_{{sub}}_catalogue.json')))

#######################################
# DATA LOCATION: MODELS, OBS AND METRICS OUTPUT
# ---------------------------------------------
# Templates for model climatology files
test_data_path = os.path.join(
  "${results_dir}",
  "climo",
  "${case_id}")
test_dic = json.load(open(os.path.join("${results_dir}",'{}_{{sub}}_clim_catalogue.json'.format(test_data_dir))))
template = test_dic['ts'][product]['template']
filename_template = template.replace('ts',"%(variable)").replace(product,"%(model)")
del(test_dic)

#######################################
# ROOT PATH FOR OBSERVATIONS
reference_data_set = list('{{ obs_sets }}'.split(","))
reference_data_path = os.path.join("${results_dir}","climo","${case_id}")
observation_file = os.path.join("${results_dir}",'{}_{{sub}}_clim_catalogue.json'.format(ref_data_dir))
custom_observations  = os.path.abspath(observation_file)
if not os.path.exists(custom_observations):
  sys.exit("ERROR: observation climatology file is missing....")

#######################################
# DIRECTORY AND FILENAME FOR OUTPUTING METRICS RESULTS
metrics_in_single_file = 'n'  #  'y' or 'n'
metrics_output_path = os.path.join(
    "${results_dir}",
    "metrics_results",
    "mean_climate",
    mip,
    exp,
    "%(case_id)"
)  # All SAME FILE
############################################################
# DIRECTORY WHERE TO PUT INTERPOLATED MODELS' CLIMATOLOGIES
diagnostics_output_path= os.path.join(
    "${results_dir}",
    "diagnostic_results",
    "mean_climate",
    mip,
    exp,
    "%(case_id)"
)

###########################################
# Templates for MODEL land/sea mask (sftlf)
# depracated in new version of pcmdi
#############################################
generate_sftlf = {{ generate_sftlf }}
os.path.join("${fixed_dir}","sftlf_%(model).nc")
test_clims_interpolated_output = diagnostics_output_path

{%- endif %}

{%- if "variability_mode" in subset  %}
############################################################
#parameter setup specific for mode variability metrics
############################################################
mip = test_cmip_name.split(".")[0]
exp = test_cmip_name.split(".")[1]
product = test_cmip_name.split(".")[2]

{% if run_type == "model_vs_obs" %}
modnames = [ test_cmip_name.split(".")[2] ]
{% elif run_type == "model_vs_model" %}
modnames = [ test_cmip_name.split(".")[2], ref_cmip_name.split(".")[2] ]
{%- endif %}

realm = test_cmip_name.split(".")[3]
realization = realm

msyear    = test_start_yr
meyear    = test_end_yr
osyear    = ref_start_yr
oeyear    = ref_end_yr

seasons   = list('{{ seasons }}'.split(","))
frequency = '{{ frequency }}'

#from configuration file
varOBS = '{{vars}}'
varModel = '{{vars}}'
ObsUnitsAdjust = {{ ObsUnitsAdjust }}
ModUnitsAdjust = {{ ModUnitsAdjust }}

# If True, maskout land region thus consider only over ocean
landmask = {{ landmask }}

#open dictional file to locate model and reference files
test_dic = json.load(open(os.path.join("${results_dir}",'{}_{{sub}}_mon_catalogue.json'.format(test_data_dir))))
modpath = test_dic[varModel]['file_path']
model = test_dic[varModel]['model']
if model != product:
  print("warning: model {} in dataset differ from user setup {}".format(model,product))
  print("warning: use model in datasets to continue....")
  modnames = [model]
del (test_dic)

#setup template for fixed files (e.g. land/sea mask)
modpath_lf = os.path.join("${fixed_dir}","sftlf_%(model).nc")

#open dictional file to locate reference data
ref_dic = json.load(open(os.path.join("${results_dir}",
                                      '{}_{{sub}}_mon_catalogue.json'.format(ref_data_dir))))
reference_data_name = ref_dic[varOBS]['model']
reference_data_path = ref_dic[varOBS]['file_path']

#update time for observation if different
ref_syear = str(ref_dic[varOBS]['start_yymm'])[0:4]
ref_eyear = str(ref_dic[varOBS]['end_yymm'])[0:4]
if int(ref_syear) > osyear:
  osyear = int(ref_syear)
if int(ref_eyear) < oeyear:
  oeyear = int(ref_eyear)
del(ref_dic,ref_syear,ref_eyear)

#######################################

# If True, remove Domain Mean of each time step
RmDomainMean = {{ RmDomainMean }}

# If True, consider EOF with unit variance
EofScaling = {{ EofScaling }}

# Conduct CBF analysis
CBF = {{ CBF }}

# Conduct conventional EOF analysis
ConvEOF = {{ ConvEOF }}

# Generate CMEC compliant json
cmec = {{ cmec }}

# Update diagnostic file if exist
update_json = {{ update_json }}

#######################################
results_dir = os.path.join(
    "${results_dir}",
    "%(output_type)",
    "variability_modes",
    "%(mip)",
    "%(exp)",
    "${case_id}",
    "%(variability_mode)",
    "%(reference_data_name)",
)
{%- endif %}

{%- if "enso" in subset %}
############################################################
#parameter setup specific for enso metrics
############################################################
mip = test_cmip_name.split(".")[0]
exp = test_cmip_name.split(".")[1]

{% if run_type == "model_vs_obs" %}
modnames = [ test_cmip_name.split(".")[2] ]
{% elif run_type == "model_vs_model" %}
modnames = [ test_cmip_name.split(".")[2], ref_cmip_name.split(".")[2] ]
{%- endif %}

realm = test_cmip_name.split(".")[3]
realization = realm

msyear = test_start_yr
meyear = test_end_yr

osyear = ref_start_yr
oeyear = ref_end_yr

#######################################
# Model (test)
# setup template for fixed files (e.g. land/sea mask)
modpath_lf = os.path.join("${fixed_dir}","sftlf_%(model).nc")
# construct model template
test_dic = json.load(open(os.path.join("${results_dir}",'{}_{{sub}}_mon_catalogue.json'.format(test_data_dir))))
vv0 = list(test_dic.keys())[0]
tableId = test_dic[vv0]['tableId']
modpath = os.path.join(
      test_data_dir,
      "%(mip).%(exp).%(model).%(realization)."+tableId+".%(variable)."
    + '{:04d}{:02d}-{:04d}{:02d}'.format(msyear,1,meyear,12)
    + ".nc")
del(test_dic,vv0)

# OBSERVATIONS
reference_data_path = {}
reference_data_lf_path = {}
#orgnize obs catalog
ref_dic = json.load(open(os.path.join("${results_dir}",'{}_{{sub}}_mon_catalogue.json'.format(ref_data_dir))))
for var in ref_dic:
  refname = ref_dic[var]['model']
  if refname not in reference_data_path.keys():
    reference_data_path[refname] = {}
  reference_data_path[refname][var] = {'template': ref_dic[var]['template']}
  #land/sea mask
  reference_data_lf_path[refname] = os.path.join("${fixed_dir}",'sftlf.{}.nc'.format(refname))
  #update time information(minimum overlap)
  ref_syear = str(ref_dic[var]['start_yymm'])[0:4]
  ref_eyear = str(ref_dic[var]['end_yymm'])[0:4]
  if int(ref_syear) > osyear:
    osyear = int(ref_syear)
  if int(ref_eyear) < oeyear:
    oeyear = int(ref_eyear)
  del(refname)
del(ref_dic)

#document the observation catalogue
obs_cmor = True
obs_cmor_path = ref_data_dir
obs_catalogue = 'obs_info_catalogue.json'
json.dump(reference_data_path,
          open(obs_catalogue,"w"),
          sort_keys=True,
          indent=4,
          separators=(",", ": "))
del(reference_data_path)

# METRICS COLLECTION (ENSO_perf, ENSO_tel, ENSO_proc)
# will set in main driver
# metricsCollection = ENSO_perf  # ENSO_perf, ENSO_tel, ENSO_proc

# OUTPUT
results_dir = os.path.join(
    "${results_dir}",
    "%(output_type)",
    "enso_metric",
    "%(mip)",
    "%(exp)",
    "${case_id}",
    "%(metricsCollection)",
)

json_name = "%(mip)_%(exp)_%(metricsCollection)_${case_id}_%(model)_%(realization)"

netcdf_name = json_name

{%- endif %}

EOF
{%- endif %}

################################################################

# Run PCMDI Diags
echo
echo ===== RUN PCMDI DIAGS =====
echo

# Prepare configuration file
cat > pcmdi.py << EOF
import os
import glob
import json
import re
import sys
import cdms2
import psutil
import numpy as np
import collections
import subprocess
import time
import pcmdi_metrics
from pcmdi_metrics.utils import StringConstructor
from argparse import RawTextHelpFormatter
from shutil import copyfile
from re import split
from itertools import chain
from subprocess import Popen, PIPE, call

{%- if "mean_climate" in subset %}
from mean_climate_plot_parser import (
    create_mean_climate_plot_parser,
)
from mean_climate_plot_driver import (
    mean_climate_metrics_plot,
)
{%- endif %}

def childCount():
    current_process = psutil.Process()
    children = current_process.children()
    return(len(children))

def generate_land_sea_mask(data_file,outpath):
    data_dic = json.load(open(data_file))
    for var in data_dic:
      model = data_dic[var]['model']
      mpath = data_dic[var]['file_path']
      mpath_lf = os.path.join(outpath,"sftlf.{}.nc".format(model))
      # generate land/sea mask if not exist
      if not os.path.exists(mpath_lf):
        print("generate land/sea mask file....")
        return_code = call(['python','process_sftlf.py',var,model,mpath,mpath_lf],text=False)
      else:
        return_code = 0
      del(model,mpath,mpath_lf)
    del(data_dic)

    return return_code

{%- if "mean_climate" in subset %}
def calculate_climatology(method,start_yr,end_yr,data_dic,out_dic,
                          outpath,multiprocessing,num_workers):

  #first check the monthly data dictionary
  if not os.path.exists(data_dic):
    exit("ERROR: monthly data dictionary file not found...")
  else:
    data_dic = json.load(open(data_dic))

  if not os.path.exists(outpath):
    os.makedirs(outpath,mode=0o777)

  #####################################
  #calculate annual cycle climatology
  #####################################
  clim_dic = collections.OrderedDict()
  lstcmd = []; lstcm0 = []; lstcm1 = []; lstcm2 = []
  for var in data_dic.keys():
    cyms = '{:04d}-{:02d}'.format(start_yr,1)
    cyme = '{:04d}-{:02d}'.format(end_yr,12)
    if int(data_dic[var]['start_yymm']) > (start_yr*100+1):
      cyms = '{}-{}'.format(str(data_dic[var]['start_yymm'])[0:4],
                            str(data_dic[var]['start_yymm'])[4:6])
    if int(data_dic[var]['end_yymm']) < (end_yr*100+12):
      cyme = '{}-{}'.format(str(data_dic[var]['end_yymm'])[0:4],
                            str(data_dic[var]['end_yymm'])[4:6])
    infile = data_dic[var]['file_path']
    if os.path.exists(infile):
      if method == "pcmdi":
        #reform the output file template
        outfile = ".".join(data_dic[var]['template'].split(".")[:-2]) + ".nc"
        cmd = (" ".join(["pcmdi_compute_climatologies.py",
                         "--start", cyms,
                         "--end", cyme,
                         "--var", var,
                         "--infile", infile,
                         "--outpath", outpath+"/",
                         "--outfilename", outfile ]))
        lstcmd.append(cmd); del(cmd,outfile)
      else:
        # use nco to process mean climatology
        # middle month days from January to February
        dofm = [15,46,74,105,135,166,196,227,258,288,319,349]
        #create a temporary directory to save temporary files
        if not os.path.exists("tmpnco"):
          os.mkdir("tmpnco",mode=0o777)
        #derive annual cycle climate mean
        for imon,mday in enumerate(dofm):
          tmpfile = os.path.join('tmpnco',"{}_tmp_{:02d}-clim.nc".format(var,imon+1))
          cmd = (" ".join(['ncra -O -h -F -d',
                           'time,{},,12'.format(imon+1),
                           infile,tmpfile]))
          lstcmd.append(cmd)
          cm0 = (" ".join(['ncatted -O -h -a',
                           'units,time,o,c,"days since 0001-01-01 00:00:0.0"',
                           tmpfile,tmpfile]))
          lstcm0.append(cm0)
          cm1 = (" ".join(['ncap2 -O -h -s',
                           "'time=time*0+{};defdim({},{});time_bnds=make_bounds(time,{},{})'".format(
                           mday,'"bnds"',2,'\$bnds','"time_bnds"'),
                           tmpfile,tmpfile]))
          lstcm1.append(cm1); del(cmd,cm0,cm1,tmpfile)
        #derive seasonal and annual mean
        for season in ["AC", "DJF", "JJA", "MAM", "SON", "ANN"]:
          period = "{}-{}".format(cyms.replace("-",""),cyme.replace("-",""))
          outpre = ".".join(data_dic[var]['template'].split(".")[:-2])
          outfile = os.path.join(outpath,".".join([outpre,"{}.{}.{}.nc".format(period,season,"${case_id}")]))
          if season == "AC":
            cm2 = (" ".join(["ncrcat -O -v {} -d time,0,".format(var),
                             os.path.join('tmpnco',"{}_*_*-clim.nc".format(var)),
                             outfile]))
          elif season == "DJF":
            cm2 = (" ".join(["ncra -O -h",
			     os.path.join('tmpnco',"{}_*_12-clim.nc".format(var)),
			     os.path.join('tmpnco',"{}_*_01-clim.nc".format(var)),
			     os.path.join('tmpnco',"{}_*_02-clim.nc".format(var)),
                             outfile]))
          elif season == "JJA":
            cm2 = (" ".join(["ncra -O -h",
                             os.path.join('tmpnco',"{}_*_06-clim.nc".format(var)),
			     os.path.join('tmpnco',"{}_*_07-clim.nc".format(var)),
                             os.path.join('tmpnco',"{}_*_08-clim.nc".format(var)),
                             outfile]))
          elif season == "MAM":
            cm2 = (" ".join(["ncra -O -h",
                             os.path.join('tmpnco',"{}_*_03-clim.nc".format(var)),
			     os.path.join('tmpnco',"{}_*_04-clim.nc".format(var)),
			     os.path.join('tmpnco',"{}_*_05-clim.nc".format(var)),
                             outfile]))
          elif season == "SON":
            cm2 = (" ".join(["ncra -O -h",
                             os.path.join('tmpnco',"{}_*_09-clim.nc".format(var)),
			     os.path.join('tmpnco',"{}_*_10-clim.nc".format(var)),
                             os.path.join('tmpnco',"{}_*_11-clim.nc".format(var)),
                             outfile]))
          elif season == "ANN":
            cm2 = (" ".join(["ncra -O -h",
                             os.path.join('tmpnco',"{}_*_*-clim.nc".format(var)),
                             outfile]))
          lstcm2.append(cm2); del(cm2,period,outfile,outpre)
      #document climatology info in dictionary file#
      period = "{}-{}".format(cyms.replace("-",""),cyme.replace("-",""))
      template = ".".join(data_dic[var]['template'].split(".")[:-2]) + \
                 ".{}.AC.{}.nc".format(period,"${case_id}")
      clim_dic[var] = {data_dic[var]['exp']   : data_dic[var]['model'],
                       data_dic[var]['model'] : {'template'  : template,
                                                 'period'    : period,
                                                 'data_path' : outpath}}
  #save climatology dictionary
  json.dump(clim_dic,
	    open(out_dic,"w"),
            sort_keys=True,
            indent=4,
            separators=(",", ": "))

  #finally process the data in parallela
  if method == "pcmdi":
    print("Number of jobs starting is ", str(len(lstcmd)))
    procs = []
    for i,p in enumerate(lstcmd):
      print('running %s' % (str(p)))
      proc = Popen(p, stdout=PIPE, shell=True)
      if multiprocessing == True:
        procs.append(proc)
        while (childCount() > num_workers):
          time.sleep(0.25)
          [pp.communicate() for pp in procs] # this will get the exit code
          procs = []
        else:
          if (i == len(lstcmd)-1):
            try:
              outs, errs = proc.communicate()
              if proc.returncode == 0:
                print("stdout = {}; stderr = {}".format(str(outs),str(errs)))
              else:
                exit("ERROR: subprocess {} failed".format(str(lstcmd[i])))
            except:
              break
      else:
        return_code = proc.communicate()
        if return_code != 0:
          exit("Failed to run {}".format(str(p)))
  elif method == "nco":
    lstall = list(chain(lstcmd,lstcm0,lstcm1,lstcm2))
    lensub = [len(lstcmd),len(lstcm0),len(lstcm1),len(lstcm2)]
    lensub = np.cumsum(lensub) - 1
    print("Number of jobs starting is ", str(len(lstall)))
    procs = []
    for i,p in enumerate(lstall):
      print('running %s' % (str(p)))
      proc = Popen(p, stdout=PIPE, shell=True)
      if multiprocessing == True:
        procs.append(proc)
        while (childCount() > num_workers):
          time.sleep(0.25)
          [pp.communicate() for pp in procs] # this will get the exit code
          procs = []
        else:
          if (i == len(lstall)-1):
            try:
              outs, errs = proc.communicate()
              if proc.returncode == 0:
                print("stdout = {}; stderr = {}".format(str(outs),str(errs)))
              else:
                exit("ERROR: subprocess {} failed".format(str(lstall[i])))
            except:
              break
      else:
        return_code = proc.communicate()
        if return_code != 0:
          exit("Failed to run {}".format(str(p)))
    # clean the temporary files
    for tmpfil in glob.glob(os.path.join('tmpnco',"_*_*-clim.nc".format(var))):
      if os.path.exists(tmpfil):
        os.remove(tmpfil)

  # add a delay to ensure the processing fully done
  time.sleep(1)
  print("done submitting")
  del(lstcmd,lstcm0,lstall,lstcm1,lstcm2,clim_dic,data_dic)

  return

def calculate_derived_variable(var,data_dic,data_path):
  ####################################################
  #this function is used to calculate a quantity given
  #the data documented in the data_dic passed by user
  #derived_variable.json is a file documen the rules to
  #calculate the required diagnostic variables
  #####################################################
  derive_dic = json.load(open("derived_variable.json"))
  vsublist = []; operator = []
  #collect the variable and operation rulse for derivation
  for vv in derive_dic[var]:
    vsublist.append(vv)
    operator.append(derive_dic[var][vv])

  #now search data file and judge if the derivation is possible
  l_derive = True
  for i,vv in enumerate(vsublist):
    infile = data_dic[vv]['data_path']
    if i == 0:
     outfile = infile.replace(vv,var)
    if (not os.path.exists(infile)) or (os.path.exists(outfile)):
      l_derive = False

  # finally do derivation
  if l_derive:
    for i,vv in enumerate(derive_dic[var].keys()):
      infile = data_dic[vv]['data_path']
      f = cdms2.open(infile)
      if i == 0:
        d = f(vv) * operator[i]
      else:
        d = d + f(vv) * operator[i]
      f.close()
      del(infile)
    f = cdms2.open(outfile,'w')
    f.write(d)
    f.close()
    del(d,outfile,f)
    outdic = {'template'  : outfile.split("/")[-1],
              'data_path' : outfile}
  del(derive_dic,vsublist,operator)

  return outdic, outfile

{%- endif %}

def main ():
  start_yr = int('${Y1}')
  end_yr = int('${Y2}')
  num_years = end_yr - start_yr + 1

  num_workers = {{ num_workers }}
  multiprocessing = {{multiprocessing}}

  # Model
  # Test data directory
{% if run_type == "model_vs_obs" %}
  test_data_dir = 'ts'
{% elif run_type == "model_vs_model" %}
  test_data_dir = 'ts_test'
{%- endif %}
  test_name = '${case}'
  test_start_yr = start_yr
  test_end_yr = end_yr
  test_dir_source='{{ output }}/post/atm/{{ grid }}/cmip_ts/monthly'
  test_cmip_name = '{{ cmip_name }}'

  # Ref
{% if run_type == "model_vs_obs" %}
  # Obs
  reference_dir_source = '{{ obs_ts }}'
  ref_data_dir = 'ts_ref'
  ref_start_yr = {{ ref_start_yr }}
  ref_end_yr = ref_start_yr + num_years - 1
  if (ref_end_yr <= {{ ref_final_yr }}):
    ref_end_yr = ref_end_yr
  else:
    ref_end_yr = {{ ref_final_yr }}
{% elif run_type == "model_vs_model" %}
  # Reference
  reference_dir_source = '{{ reference_data_path_ts }}'
  ref_data_dir = 'ts_ref'
  ref_name = '${ref_name}'
  short_ref_name = '{{ short_ref_name }}'
  ref_start_yr = {{ ref_start_yr }}
  ref_end_yr = {{ ref_final_yr }}
  ref_cmip_name = '{{ cmip_name_ref }}'

  # Optionally, swap test and reference model
  if {{ swap_test_ref }}:
    test_data_dir, ref_data_dir = ref_data_dir, test_data_dir
    test_name, ref_name = ref_name, test_name
    short_test_name, short_ref_name = short_ref_name, short_test_name
    ref_cmip_name, test_cmip_name = test_cmip_name, ref_cmip_name
{%- endif %}

  ################################################################################
  # land/sea mask is needed in PCMDI diagnostics, check and generate it here as
  # these data are not always available for model or observations
  ################################################################################
  # Model
  test_dic = os.path.join("${results_dir}",'{}_{{sub}}_mon_catalogue.json'.format(test_data_dir))
  return_code = generate_land_sea_mask(test_dic,"${fixed_dir}")
  if return_code != 0:
    exit("Failed to generate land/sea mask...")
  del(test_dic)
  # Reference
  ref_dic = os.path.join("${results_dir}",'{}_{{sub}}_mon_catalogue.json'.format(ref_data_dir))
  return_code = generate_land_sea_mask(ref_dic,"${fixed_dir}")
  if return_code != 0:
    exit("Failed to generate land/sea mask...")
  del(ref_dic)

  # Run PCMDI for diagnostics
{%- if "mean_climate" in subset %}
  #####################################################################
  # calculate test and reference model climatology
  #####################################################################
  print("calculate mean climate diagnostics")
  outpath = os.path.join("${results_dir}","climo","${case_id}")
  method = '{{climatology_process_method}}'
  for key in ["test","ref"]:
    if key == "test":
      data_dir = test_data_dir
      start_yr = test_start_yr
      end_yr   = test_end_yr
    elif key == "ref":
      data_dir = ref_data_dir
      start_yr = ref_start_yr
      end_yr   = ref_end_yr
    data_dic = os.path.join("${results_dir}",'{}_{{sub}}_mon_catalogue.json'.format(data_dir))
    clim_dic = os.path.join("${results_dir}",'{}_{{sub}}_clim_catalogue.json'.format(data_dir))
    if method in [ "pcmdi", "PCMDI", "default" ]:
      #method 1: built in PCMDI package (may have memory issue for highres data)
      calculate_climatology("pcmdi",start_yr,end_yr,data_dic,clim_dic,outpath,multiprocessing,num_workers)
    elif method in [ "nco", "NCO", "alternate"]:
      #method 2: use nco package(default,faster)
      calculate_climatology("nco",start_yr,end_yr,data_dic,clim_dic,outpath,multiprocessing,num_workers)
    if not os.path.exists(clim_dic):
      exist("ERROR: failed to process data climatology....")
    del(data_dir,start_yr,end_yr,data_dic,clim_dic)

  #####################################################################
  # call mean_climate_driver.py to process diagnostics
  #####################################################################
  #defined regions
  regional = '{{ regional }}'
  if regional  == "y":
    default_regions = list('{{ regions }}'.split(","))
  else:
    default_regions = ["global", "NHEX", "SHEX", "TROPICS"]
  # create command list for mean climate driver
  lstcmd = []
  reg_var_dic = {}
  for vv in list("{{vars}}".split(",")):
    vkys = vv.split("-")[0]
    reg_var_dic[vkys] = default_regions
    vars = vv
    cmd = (" ".join(["mean_climate_driver.py",
                     "-p", "parameterfile.py",
                     "--vars", '{}'.format(vars)]))
    lstcmd.append(cmd); del(cmd,vars,vkys)

  #create regions for regional mean of each variable
  json.dump(reg_var_dic,
            open(os.path.join("${results_dir}",'var_region_{{sub}}_catalogue.json'),"w"),
            sort_keys=True,
            indent=4,
            separators=(",", ": "))

  #finally process the data in parallel
  print("Number of jobs starting is ", str(len(lstcmd)))
  procs = []
  if len(lstcmd) > 0:
    for i,p in enumerate(lstcmd):
      print('running %s' % (str(p)))
      proc = Popen(p, stdout=PIPE, shell=True)
      if multiprocessing == True:
        procs.append(proc)
        while (childCount() > num_workers):
          time.sleep(0.25)
          [pp.communicate() for pp in procs]
          procs = []
        else:
          if (i == len(lstcmd)-1):
            try:
              outs, errs = proc.communicate()
              if proc.returncode == 0:
                print("stdout = {}; stderr = {}".format(str(outs),str(errs)))
              else:
                exit("ERROR: subprocess {} failed".format(str(lstcmd[i])))
            except:
              break
      else:
        return_code = proc.communicate()
        if return_code != 0:
          exit("Failed to run {}".format(str(p)))

  #set a delay to avoid delay in writing process
  time.sleep(1)
  print("done submitting")
  del(reg_var_dic,regional,lstcmd)

  #generate diagnostics figures
  print("--- prepare for mean climate metrics plot ---")
  parser = create_mean_climate_plot_parser()
  parameter = parser.get_parameter(argparse_vals_only=False)
  parameter.regions = default_regions
  parameter.run_type = "${run_type}"
  parameter.period = "{}-{}".format(test_start_yr,test_end_yr)
  parameter.pcmdi_data_set = "{{pcmdi_data_set}}"
  parameter.pcmdi_data_path = os.path.join('{{pcmdi_data_path}}',"mean_climate")
  parameter.test_data_set = "{}.{}".format(test_cmip_name,"${case_id}")
  parameter.test_data_path = os.path.join("${results_dir}","metrics_results","mean_climate")
{% if run_type == "model_vs_obs" %}
  parameter.refr_data_set = ""
  parameter.refr_period = ""
  parameter.refr_data_path = ""
{% elif run_type == "model_vs_model" %}
  parameter.refr_data_set = "{}.{}".format(ref_cmip_name,"${case_id}")
  parameter.refr_period = "{}-{}".format(ref_start_yr,ref_end_yr)
  parameter.refr_data_path = os.path.join("${results_dir}","metrics_results","mean_climate")
{%- endif %}
  parameter.output_path = os.path.join("${results_dir}","graphics","mean_climate")
  parameter.ftype = '{{ figure_format }}'
  parameter.debug = {{ pmp_debug }}
  parameter.parcord_show_markers = {{parcord_show_markers}} #False
  parameter.add_vertical_line = {{portrait_vertical_line}}  #True

  #generate diagnostics figures
  print("--- generate mean climate metrics plot ---")
  mean_climate_metrics_plot(parameter)
  del(parameter)

{%- endif %}

{%- if "variability_mode" in subset %}
  print("calculate mode variability metrics")
{%- if subset == "variability_mode_atm" %}
  modes = list({{ atm_modes }})
{% elif subset == "variability_mode_cpl" %}
  modes = list({{ cpl_modes }})
{%- endif %}
  #####################################################################
  # call variability_modes_driver.py to process diagnostics
  #####################################################################
  lstcmd = []
  for variability_mode in modes:
    if variability_mode in ["NPO", "NPGO", "PSA1"]:
      eofn_obs = "2"
      eofn_mod = "2"
    elif variability_mode in ["PSA2"]:
      eofn_obs = "3"
      eofn_mod = "3"
    else:
      eofn_obs = "1"
      eofn_mod = "1"
    cmd = (" ".join(['variability_modes_driver.py',
                     '-p', "parameterfile.py",
                     '--variability_mode', variability_mode,
                     '--eofn_mod', eofn_mod,
                     '--eofn_obs', eofn_obs ]))
    lstcmd.append(cmd); del(cmd)
  #finally process the data in parallel
  print("Number of jobs starting is ", str(len(lstcmd)))
  procs = []
  for i,p in enumerate(lstcmd):
    print('running %s' % (str(p)))
    proc = Popen(p, stdout=PIPE, shell=True)
    if multiprocessing == True:
      procs.append(proc)
      while (childCount() > num_workers):
        time.sleep(0.25)
        [pp.communicate() for pp in procs] # this will get the exit code
        procs = []
      else:
        if (i == len(lstcmd)-1):
          try:
            outs, errs = proc.communicate()
            if proc.returncode == 0:
              print("stdout = {}; stderr = {}".format(str(outs),str(errs)))
            else:
              exit("ERROR: subprocess {} failed".format(str(lstcmd[i])))
          except:
            break
    else:
      return_code = proc.communicate()
      if return_code != 0:
        exit("Failed to run {}".format(str(p)))
  #set a delay to avoid delay in writing process
  time.sleep(1)
  print("done submitting")
  del(lstcmd)
{%- endif %}

{%- if "enso" in subset %}
  #####################################################################
  # call enso_driver.py to process diagnostics
  #####################################################################
  print("calculate enso metrics")
  groups = list({{ groups }})
  lstcmd = []
  for metricsCollection in groups:
    cmd = (" ".join(['enso_driver.py',
                      '-p', "parameterfile.py",
                      '--metricsCollection',metricsCollection]))
    lstcmd.append(cmd); del(cmd)
  #finally process the data in parallel
  print("Number of jobs starting is ", str(len(lstcmd)))
  procs = []
  for i,p in enumerate(lstcmd):
    print('running %s' % (str(p)))
    proc = Popen(p, stdout=PIPE, shell=True)
    procs.append(proc)
    while (childCount() > {{num_workers}}):
      time.sleep(0.25)
      [pp.communicate() for pp in procs] # this will get the exit code
      procs = []
    else:
      if (i == len(lstcmd)-1):
        try:
          outs, errs = proc.communicate()
          if proc.returncode == 0:
            print("stdout = {}; stderr = {}".format(str(outs),str(errs)))
          else:
            exit("ERROR: subprocess {} failed".format(str(lstcmd[i])))
        except:
          break
  #set a delay to avoid delay in writing process
  time.sleep(1)
  print("done submitting")
  del(lstcmd,procs)
{%- endif %}

if __name__ == "__main__":
  main()

EOF

################################
# Run diagnostics
#command="srun -n 1 python -u pcmdi.py"
command="python -u pcmdi.py"
# Run diagnostics
time ${command}
if [ $? != 0 ]; then
  cd {{ scriptDir }}
  echo 'ERROR (10)' > {{ prefix }}.status
  exit 9
fi

# Copy output to web server
echo
echo ===== COPY FILES TO WEB SERVER =====
echo

# Create top-level directory
web_dir=${www}/${case}/pcmdi_diags #/{{ sub }}
mkdir -p ${web_dir}
if [ $? != 0 ]; then
  cd {{ scriptDir }}
  echo 'ERROR (10)' > {{ prefix }}.status
  exit 10
fi

{% if machine in ['pm-cpu', 'pm-gpu'] %}
# For NERSC, make sure it is world readable
f=`realpath ${web_dir}`
while [[ $f != "/" ]]
do
  owner=`stat --format '%U' $f`
  if [ "${owner}" = "${USER}" ]; then
    chgrp e3sm $f
    chmod go+rx $f
  fi
  f=$(dirname $f)
done
{% endif %}

# Copy files
#rsync -a --delete ${results_dir} ${web_dir}/
rsync -a ${results_dir} ${web_dir}/
if [ $? != 0 ]; then
  cd {{ scriptDir }}
  echo 'ERROR (11)' > {{ prefix }}.status
  exit 11
fi

{% if machine in ['pm-cpu', 'pm-gpu'] %}
# For NERSC, change permissions of new files
pushd ${web_dir}/
chgrp -R e3sm ${results_dir}
chmod -R go+rX,go-w ${results_dir}
popd
{% endif %}

{% if machine in ['anvil', 'chrysalis'] %}
# For LCRC, change permissions of new files
pushd ${web_dir}/
chmod -R go+rX,go-w ${results_dir}
popd
{% endif %}

# Delete temporary workdir
cd ..
if [[ "${debug,,}" != "true" ]]; then
  rm -rf ${workdir}
fi

# Update status file and exit
{% raw %}
ENDTIME=$(date +%s)
ELAPSEDTIME=$(($ENDTIME - $STARTTIME))
{% endraw %}
echo ==============================================
echo "Elapsed time: $ELAPSEDTIME seconds"
echo ==============================================
rm -f {{ prefix }}.status
echo 'OK' > {{ prefix }}.status
exit 0
