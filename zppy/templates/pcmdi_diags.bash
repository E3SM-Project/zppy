#!/bin/bash
{% include 'slurm_header.sh' %}

{{ environment_commands }}

# Turn on debug output if needed
debug={{ debug }}
if [[ "${debug,,}" == "true" ]]; then
  set -x
fi

# Need this setup as otherwise can not generate diagnostics
export UCX_SHM_DEVICES=all # or not set UCX_NET_DEVICES at all

# Make sure UVCDAT doesn't prompt us about anonymous logging
export UVCDAT_ANONYMOUS_LOG=False

# Script dir
cd {{ scriptDir }}

# Get jobid
id=${SLURM_JOBID}

# Update status file
STARTTIME=$(date +%s)
echo "RUNNING ${id}" > {{ prefix }}.status

# Basic definitions
case="{{ case }}"
short="{{ short_name }}"
www="{{ www }}"
y1={{ year1 }}
y2={{ year2 }}
Y1="{{ '%04d' % (year1) }}"
Y2="{{ '%04d' % (year2) }}"
{% if run_type == "model_vs_model" %}
ref_Y1="{{ '%04d' % (ref_year1) }}"
ref_Y2="{{ '%04d' % (ref_year2) }}"
{%- endif %}
run_type="{{ run_type }}"
tag="{{ tag }}"

results_dir=${tag}_${Y1}-${Y2}

ref_name={{ ref_name }}

#info for pcmdi specific data structure
case_id=v$(date '+%Y%m%d')

# Create temporary workdir
workdir=`mktemp -d tmp.${id}.XXXX`
cd ${workdir}

# Create results directory
if [ ! -d ${results_dir} ];then
  mkdir -p ${results_dir}
fi
#directory to save land/sea mask generated by pcmdi
fixed_dir="${results_dir}/fixed"
if [ ! -d ${fixed_dir} ];then
  mkdir -p ${fixed_dir}
fi

# Prepare data files for pcmdi diagnostics, which is achieved by two steps:
# (a) convert e3sm output to cmip type, which used the "e3sm_to_cmip" function
#     available at zppy (modifications are made to process more variables and
#     3D fileds at fixed pressure levels).
# (b) locate observations in e3sm diagnostics and convert them to the pcmdi preferred
#     data format
#file to specify reference data used to derive the diagnostic metrics
cat > reference_alias.json << EOF
{% include reference_alias %}
EOF
#regions specified to derive global/regional mean metrics
cat > regions_specs.json << EOF
{% include regions_specs %}
EOF
#file include derived variables
cat > derived_variable.json << EOF
{% include derived_variable %}
EOF
#file to genereate land/sea mask data if not available
cat > generate_sftlf.py << EOF
{% include process_sftlf %}
EOF

# script for pcmdi pre-processing
cat > collect_data.py << EOF
import os
import pprint
import shlex
import requests
import subprocess
import json
import sys
import re
import glob
import errno
import shutil
import numpy as np
import collections
import cdms2
import gc
import time

def combine_time_series(varibles,start_yr,end_yr,num_years,
                        mip,exp,realm,product,dir_source,output_path):

  if not os.path.exists(output_path):
    os.makedirs(output_path)

  # list of model data dictionary
  mod_out = collections.OrderedDict()

  var_list = []
  for key in varibles:
    if "_" in key or "-" in key:
      var = re.split("_|-", key)[0]
    else:
      var = key
    varin = var
    fpaths = sorted(glob.glob(os.path.join(dir_source,var+"_*.nc")))
    if len(fpaths) < 1:
      if var == "sst":
        varin = "ts"
      elif var == "taux":
        varin = "tauu"
      elif var == "tauy":
        varin = "tauv"
      fpaths = sorted(glob.glob(os.path.join(dir_source,varin+"_*.nc")))

    if len(fpaths) > 0 :
      if var in ["areacella", "sftlf", "orog"]:
        for fpath in fpaths:
          output = os.path.join(output_path,"{}_fx_{}.nc".format(var,model))
          os.rename(fpath,output)
          del(output)
      else:
        if varin != fpaths[0].split("/")[-1].split("_")[0]:
          varin = varf
        tableId = fpaths[0].split("/")[-1].split("_")[1]
        yms = '{:04d}01'.format(start_yr)
        yme = '{:04d}12'.format(end_yr)
        fname = "{}.{}.{}.{}.{}.{}.{}-{}.nc".format(
                 mip,exp,product.replace(".","-"),realm,tableId,var,yms,yme)
        output = os.path.join(output_path,fname)
        if not os.path.exists(output):
          cmd_list = []
          cmd_list.append('ncrcat -d time,"{}-01-01","{}-12-31"'.format(start_yr,end_yr))
          for fpath in fpaths:
            cmd_list.append(fpath)
          cmd_list.append(output)
          ############################################################
          #call nco to combine multiple files
          return_code = subprocess.call(' '.join(cmd_list),shell=True)
          if return_code != 0:
            exit("Failed to run ncrcat to combine files ...")
          del(cmd_list)
          if varin != var:
            print("input variable ",varin)
            print("required variable: ",var)
            return_code = subprocess.call(
                            'ncrename -v {},{} {}'.format(varin,var,output),
                            shell=True,text=False)
            if return_code != 0:
              exit("Failed to convert {} to {} ...".format(varin,var))

        ############################################################
        var_list.append(var)
        #record the test model data information
        mod_out[var] = { "mip"        : mip,
                         "exp"        : exp,
                         "realization": realm,
                         "tableId"    : tableId,
                         "model"      : product.replace(".","-"),
                         "file_path"  : output,
                         "template"   : fname,
                         "start_yymm" : yms,
                         "end_yymm"   : yme,
                         "varin"      : varin }
        #check if the data file is complete and get information about data
        mod_out[var]['RefTrackingDate'] = time.ctime(os.path.getmtime(output.strip()))
        md5 = os.popen("md5sum " + output)
        mod_out[var]['MD5sum'] = md5.readlines()[0].split()[0]
        f = cdms2.open(output)
        try:
          d = f(var)
        except:
          if var not in f.listvariable():
            exit("ERROR: {} not exist in file {}".format(var,output))
          else:
            exit("ERROR: {} can not be extracted from file {}".format(var,output))
        else:
          shape = d.shape
          shape = repr(d.shape)
          mod_out[var]['shape'] = shape
          del(d,shape)
          f.close()
        del (f,fname,yms,yme,md5,output,tableId)
    del(fpaths)
    gc.collect()
  return var_list, mod_out

def locate_ts_observation (variables,obs_sets,start_yr,end_yr,input_path,output_path):

  if not os.path.exists(output_path):
    os.makedirs(output_path)

  # find observational data avaiable in e3sm_diags
  mip = "obs"
  realization = "00"
  tableId = "Amon"
  obs_sets = list('{{ reference_sets }}'.split(","))
  obs_dic = json.load(open(os.path.join('.','reference_alias.json')))
  obs_out = collections.OrderedDict()
  var_list = []
  for i,key in enumerate(variables):
    if "_" in key or "-" in key:
      var = key.split("_|-", var)[0]
    else:
      var = key
    varin = var
    varin = var
    if len(obs_sets) != len(variables):
      option = obs_sets[0]
    else:
      option = obs_sets[i]
    if "default" in obs_sets or "alternate" in obs_sets:
      obstag = obs_dic[var][option]
    else:
      inv_map = {v: k for k, v in obs_dic[var].items()}
      if len(obs_sets) != len(variables):
        obstag = obs_sets[0]
      else:
        obstag = obs_sets[i]
      option = inv_map[obstag]
      del(inv_map)

    if "ceres_ebaf" in obstag:
      if var == "rltcre":
        varin = "toa_cre_lw"
      elif var == "rstcre":
        varin = "toa_cre_sw"
      elif var == "rtmt":
        varin = "toa_net_all_mon"
      else:
        varin = var
      fpaths = sorted(glob.glob(os.path.join(input_path,
                      obstag.replace('ceres_ebaf','ceres_ebaf*'),
                      varin+"_*.nc")))
    else:
      fpaths = sorted(glob.glob(os.path.join(input_path,obstag,var+"_*.nc")))
      if len(fpaths) < 1:
        if var == "pr" :
          varin = "PRECT"
        elif var == "sst" :
          varin = "ts"
        elif var == "sfcWind":
          varin = "si10"
        elif var == "taux":
          varin = "tauu"
        elif var == "tauy":
          varin = "tauv"
        fpaths = sorted(glob.glob(os.path.join(input_path,obstag,varin+"_*.nc")))

    if len(fpaths) > 0 and os.path.exists(fpaths[0]):
      fname = fpaths[0].split("/")[-1]
      obsnm = fpaths[0].split("/")[-2]
      yms = '{:04d}{:02d}'.format(start_yr,1)
      yme = '{:04d}{:02d}'.format(end_yr,12)
      if int(yms) > int(fname.split("_")[-2][0:6]):
        yms = fname.split("_")[-2][0:6]
      if int(yme) < int(fname.split("_")[-1][0:6]):
        yme = fname.split("_")[-1][0:6]
      #rename file into pcmdi preferred format
      fname = "{}.{}.{}.{}.{}.{}.{}-{}.nc".format(
               mip,option,obsnm.replace(".","-"),realization,tableId,var,yms,yme)
      output = os.path.join(output_path,fname)
      if not os.path.exists(output):
        shutil.copy(fpaths[0],output)
        if varin != var:
          print("input variable ",varin)
          print("required variable: ",var)
          return_code = subprocess.call(
                          'ncrename -v {},{} {}'.format(varin,var,output),
                          shell=True,text=False)
          if return_code != 0:
            exit("Failed to convert {} to {} ...".format(varin,var))

      #record the observation information
      obs_out[var] = { "mip"         : mip,
                       "exp"         : option,
                       "realization" : realization,
                       "tableId"     : tableId,
                       "model"       : obsnm,
                       "file_path"   : output,
                       "template"    : fname,
                       "start_yymm"  : yms,
                       "end_yymm"    : yme,
                       "varin"       : varin}
      #check if the data file is complete and get information about data
      obs_out[var]['RefTrackingDate'] = time.ctime(os.path.getmtime(output.strip()))
      md5 = os.popen("md5sum " + output)
      obs_out[var]['MD5sum'] = md5.readlines()[0].split()[0]
      f = cdms2.open(output)
      try:
        d = f(var)
      except:
        if var not in f.listvariable():
          exit("ERROR: {} not exist in file {}".format(var,output))
        else:
          exit("ERROR: {} can not be extracted from file {}".format(var,output))
      else:
        shape = d.shape
        shape = repr(d.shape)
        obs_out[var]['shape'] = shape
        del(d,shape)
        f.close()
      var_list.append(var)
      del (f,fname,output,md5)
      gc.collect()
    else :
      print("warning: reference data not found for", var)

  return var_list, obs_out

def main():

  #basic information
  short_name = '${short}'
  start_yr = int('${Y1}')
  end_yr = int('${Y2}')
  num_years = end_yr - start_yr + 1

  # Model
  # Test data path
{% if run_type == "model_vs_obs" %}
  test_data_path = 'ts'
{% elif run_type == "model_vs_model" %}
  test_data_path = 'ts_test'
{%- endif %}
  test_name = '${case}'
  short_test_name = short_name
  test_start_yr = start_yr
  test_end_yr = end_yr
  test_dir_source='{{ output }}/post/atm/{{ grid }}/cmip_ts/monthly'

  #info for pcmdi data structure
  test_mip = '{{ mip }}'
  test_exp = '{{ exp }}'
  test_realm = '{{ realization }}'
  test_product = '{{ product }}'

  #Ref
{% if run_type == "model_vs_obs" %}
  # Obs
  reference_dir_source = '{{ obs_ts }}'
  ref_data_path = 'ts_ref'
  ref_start_yr = {{ ref_start_yr }}
  ref_end_yr = ref_start_yr + num_years - 1
  if (ref_end_yr <= {{ ref_final_yr }}):
    ref_end_yr = ref_end_yr
  else:
    ref_end_yr = {{ ref_final_yr }}
{% elif run_type == "model_vs_model" %}
  # Reference
  reference_dir_source = '{{ reference_data_path_ts }}'
  ref_data_path = 'ts_ref'
  ref_name = '${ref_name}'
  short_ref_name = '{{ short_ref_name }}'
  ref_start_yr = {{ ref_start_yr }}
  ref_end_yr = {{ ref_final_yr }}
  #info for pcmdi data structure
  ref_mip = '{{ ref_mip }}'
  ref_exp = '{{ ref_exp }}'
  ref_realm = '{{ ref_realization }}'
  ref_product = '{{ ref_product }}'

  # Optionally, swap test and reference model
  if {{ swap_test_ref }}:
    test_data_path, ref_data_path = ref_data_path, test_data_path
    test_name, ref_name = ref_name, test_name
    short_test_name, short_ref_name = short_ref_name, short_test_name
    ref_mip, test_mip = test_mip, ref_mip
    ref_exp, test_exp = test_exp, ref_exp
    ref_realm, test_realm = test_realm, ref_realm
    ref_product, test_product = test_product, ref_product
{%- endif %}

  ################################################################
  # process test model data for comparision
  ################################################################
  print("process test model data for comparision")
  #variable list in configuration file
  variables = list("{{ vars }}".split(","))
  cmor_vars, test_data_dic = combine_time_series(
                               variables, test_start_yr,test_end_yr,
                               int({{ts_num_years}}), test_mip,
                               test_exp, test_realm, test_product,
                               test_dir_source, test_data_path)

  # Save test model data information required for next step
  json.dump(test_data_dic,
	    open(os.path.join('${results_dir}',
                              '{}_{{sub}}_mon_catalogue.json'.format(test_data_path)), "w"),
            sort_keys=True,
            indent=4,
            separators=(",", ": "))
  del(test_data_dic,variables)
  print("# of cmorized model variables: ", len(cmor_vars))

  ################################################################
  # process reference data for comparison
  ################################################################
  print("process reference obs/model data for comparision")
{% if run_type == "model_vs_obs" %}
  obs_sets = list('{{ reference_sets }}'.split(","))
  refr_vars, obs_data_dic = locate_ts_observation (
                               cmor_vars,obs_sets,
                               ref_start_yr,ref_end_yr,
                               reference_dir_source,
                               ref_data_path)
  # Save observational information required for next step
  json.dump(obs_data_dic,
	    open(os.path.join('${results_dir}','{}_{{sub}}_mon_catalogue.json'.format(ref_data_path)),"w"),
            sort_keys=True,
            indent=4,
            separators=(",", ": "))
  del(obs_data_dic,obs_sets)
  print("# of variables with observations: ", len(refr_vars))
  del(refr_vars,cmor_vars)

{% elif run_type == "model_vs_model" %}
  #variable list in configuration file
  variables = list("{{ vars }}".split(","))
  refr_vars, refr_data_dic = combine_time_series(
                               variables, ref_start_yr,ref_end_yr,
                               int({{ts_num_years_ref}}), ref_mip,
                               ref_exp, ref_realm, ref_product,
                               ref_dir_source, ref_data_path)

  ref_list_out = combine_time_series(cmor_vars, ref_data_path,
                                     ref_mip, ref_exp, ref_realm, ref_product,
                                     ref_start_yr, ref_end_yr, ref_data_path)
  # Save reference information required for next step
  json.dump(ref_data_dic,
	    open(os.path.join('${results_dir}','{}_{{sub}}_mon_catalogue.json'.format(ref_data_path)),"w"),
            sort_keys=True,
            indent=4,
            separators=(",", ": "))
  del(ref_data_dic,variables)
  print("# of variables with observations: ", len(refr_vars))
  del(refr_vars,cmor_vars)

{%- endif %}

if __name__ == "__main__":
  main()

EOF

################################
# Pcmdi pre-processing to link
# required data to work directory
command="python -u collect_data.py"
time ${command}
if [ $? != 0 ]; then
  cd {{ scriptDir }}
  echo 'ERROR (9)' > {{ prefix }}.status
  exit 9
fi

################################################################
# generate input parameter for pcmdi metrics driver
{%- if ("mean_climate" in sets) or ("variability_mode" in sets) or ("enso" in sets) %}
cat > parameterfile.py << EOF
import os
import sys
import cdutil
import datetime
import json
import subprocess

#basic information
short_name = '${short}'
start_yr = int('${Y1}')
end_yr = int('${Y2}')
num_years = end_yr - start_yr + 1

# Model
# Test data path
{% if run_type == "model_vs_obs" %}
test_data_path = 'ts'
{% elif run_type == "model_vs_model" %}
test_data_path = 'ts_test'
{%- endif %}
test_name = '${case}'
short_test_name = short_name
test_start_yr = start_yr
test_end_yr = end_yr
test_dir_source='{{ output }}/post/atm/{{ grid }}/cmip_ts/monthly'
test_mip = '{{ mip }}'
test_exp = '{{ exp }}'
test_realm = '{{ realization }}'
test_product = '{{ product }}'

# Ref
{% if run_type == "model_vs_obs" %}
# Obs
reference_dir_source = '{{ obs_ts }}'
ref_data_path = 'ts_ref'
ref_start_yr = {{ ref_start_yr }}
ref_end_yr = ref_start_yr + num_years - 1
if (ref_end_yr <= {{ ref_final_yr }}):
  ref_end_yr = ref_end_yr
else:
  ref_end_yr = {{ ref_final_yr }}
{% elif run_type == "model_vs_model" %}
# Reference
reference_dir_source = '{{ reference_data_path_ts }}'
ref_data_path = 'ts_ref'
ref_name = '${ref_name}'
short_ref_name = '{{ short_ref_name }}'
ref_start_yr = {{ ref_start_yr }}
ref_end_yr = {{ ref_final_yr }}
ref_mip = '{{ ref_mip }}'
ref_exp = '{{ ref_exp }}'
ref_realm = '{{ ref_realization }}'
ref_product = '{{ ref_product }}'
# Optionally, swap test and reference model
if {{ swap_test_ref }}:
  test_data_path, ref_data_path = ref_data_path, test_data_path
  test_name, ref_name = ref_name, test_name
  short_test_name, short_ref_name = short_ref_name, short_test_name
  ref_mip, test_mip = test_mip, ref_mip
  ref_exp, test_exp = test_exp, ref_exp
  ref_realm, test_realm = test_realm, ref_realm
  ref_product, test_product = test_product, ref_product
{%- endif %}

# shared options
case_id = '${case_id}'

# Record NetCDF output
nc_out_obs = {{ nc_out_obs }}
nc_out = {{ nc_out }}
if nc_out:
  ext = ".nc"
else:
  ext = ".xml"

user_notes = 'Provenance and results'

num_workers = {{ num_workers }}
multiprocessing = {{ multiprocessing }}
if multiprocessing:
  parallel = True
else:
  parallel = False

debug = {{ pmp_debug }}

# Generate plots
plot = {{ plot }}
plot_obs = {{ plot_obs }} # optional

# Additional settings
run_type = '{{ run_type }}'
diff_title = '{{ diff_title }}'
output_format = {{ output_format }}
output_format_subplot = {{ output_format_subplot }}

{%- if "mean_climate" in subset %}
#############################################################
#parameter setup specific for mean climate metrics
#############################################################

# Generate CMEC compliant json
cmec = {{ cmec }}

mip = test_mip
exp = test_exp
realm = test_realm
realization = realm

modver = '${case_id}'

# SIMULATION PARAMETER
period = "{:04d}{:02d}-{:04d}{:02d}".format(test_start_yr,1,test_end_yr,12)

test_data_set = [ test_product ]

# variables list to be processed
vars = []
for vv in list("{{ vars }}".split(",")):
  vars.append(vv)

# INTERPOLATION OPTIONS
target_grid = '{{ target_grid }}'  # OPTIONS: '2.5x2.5' or an actual cdms2 grid object
targetGrid = target_grid
target_grid_string = '{{ target_grid_string }}'
regrid_tool = '{{ regrid_tool }}' # OPTIONS: 'regrid2','esmf'
regrid_method = '{{ regrid_method }}' # OPTIONS: 'linear','conservative', only if tool is esmf
regrid_tool_ocn = '{{ regrid_tool_ocn }}' # OPTIONS: "regrid2","esmf"
regrid_method_ocn = ( '{{ regrid_method_ocn }}' )  # OPTIONS: 'linear','conservative', only if tool is esmf

# SAVE INTERPOLATED MODEL CLIMATOLOGIES ?
save_test_clims = {{ save_test_clims }}

#######################################
#defined regions
regions_specs = json.load(open(os.path.join(".",'regions_specs.json')))
regional = '{{ regional }}'
if regional  == "y":
  defaulat_regions = list('{{ regions }}'.split(","))
else:
  defaulat_regions = list('global,NH,SH,NHEX,SHEX,TROPICS'.split(","))

#assign regions to each variables
regions = {}
for var in vars:
  regions[var] = defaulat_regions

# CUSTOMIZE REGIONS VALUES NAMES
regions_values = {"land":100.,"ocean":0.}

#######################################
# DATA LOCATION: MODELS, OBS AND METRICS OUTPUT
# ---------------------------------------------
# Templates for model climatology files
test_dic = json.load(open(os.path.join('${results_dir}','{}_{{sub}}_clim_catalogue.json'.format(test_data_path))))
template = test_dic['ts'][test_product]['template']
test_data_path = os.path.join(
  "${results_dir}",
  "climo")
filename_template = template.replace('ts',"%(variable)").replace(test_product,"%(model)")
del(test_dic)

#######################################
# ROOT PATH FOR OBSERVATIONS
reference_data_set = list('{{ reference_sets }}'.split(","))
reference_data_path = os.path.join('${results_dir}',"climo")
observation_file = os.path.join('${results_dir}','{}_{{sub}}_clim_catalogue.json'.format(ref_data_path))
custom_observations  = os.path.abspath(observation_file)
if not os.path.exists(custom_observations):
  sys.exit("ERROR: observation climatology file is missing....")

#######################################
# DIRECTORY AND FILENAME FOR OUTPUTING METRICS RESULTS
metrics_in_single_file = 'n'  #  'y' or 'n'
metrics_output_path = os.path.join(
    "${results_dir}",
    "metrics_results",
    "mean_climate",
    mip,
    exp,
    "%(case_id)"
)  # All SAME FILE
############################################################
# DIRECTORY WHERE TO PUT INTERPOLATED MODELS' CLIMATOLOGIES
diagnostics_output_path= os.path.join(
    "${results_dir}",
    "diagnostic_results",
    "mean_climate",
    mip,
    exp,
    "%(case_id)"
)

###########################################
# Templates for MODEL land/sea mask (sftlf)
# depracated in new version of code
#############################################
generate_sftlf = {{ generate_sftlf }}
sftlf_filename_template = "sftlf_%(model).nc"
test_clims_interpolated_output = diagnostics_output_path

{%- endif %}

{%- if "variability_mode" in subset  %}
############################################################
#parameter setup specific for mode variability metrics
############################################################
mip = test_mip
exp = test_exp
realm = test_realm
realization = realm

modnames = [ test_product ]

msyear    = test_start_yr
meyear    = test_end_yr
osyear    = ref_start_yr
oeyear    = ref_end_yr

seasons   = list('{{ seasons }}'.split(","))
frequency = '{{ frequency }}'

#from configuration file
varOBS = '{{vars}}'
varModel = '{{vars}}'
ObsUnitsAdjust = {{ ObsUnitsAdjust }}
ModUnitsAdjust = {{ ModUnitsAdjust }}

# If True, maskout land region thus consider only over ocean
landmask = {{ landmask }}

#open dictional file to locate model and reference files
test_dic = json.load(open(os.path.join('${results_dir}','{}_{{sub}}_mon_catalogue.json'.format(test_data_path))))
modpath = test_dic[varModel]['file_path']
model = test_dic[varModel]['model']
del (test_dic)

if model != test_product:
  print("warning: model {} in dataset differ from user setup {}".format(model,test_product))
  print("warning: use model in datasets to continue....")
  modnames = [model]

if landmask == True:
  # generate land/sea mask if not exist
  modpath_lf = os.path.join('${fixed_dir}',"sftlf.{}.nc".format(model))
  if not os.path.exists(modpath_lf) :
    print("generate land/sea mask file....")
    return_code = subprocess.call(
                    ['python', 'generate_sftlf.py',
                     varModel, model, modpath, modpath_lf],
                  text=False)
    if return_code != 0:
      exit("Failed to generate land/sea mask...")
else:
  #setup template for fixed files (e.g. land/sea mask)
  modpath_lf = os.path.join('${fixed_dir}',"sftlf_%(model).nc")

#open dictional file to locate reference data
ref_dic = json.load(open(os.path.join('${results_dir}',
                                      '{}_{{sub}}_mon_catalogue.json'.format(ref_data_path))))
reference_data_name = ref_dic[varOBS]['model']
reference_data_path = ref_dic[varOBS]['file_path']

#update time for observation if different
ref_syear = str(ref_dic[varOBS]['start_yymm'])[0:4]
ref_eyear = str(ref_dic[varOBS]['end_yymm'])[0:4]
if int(ref_syear) > osyear:
  osyear = int(ref_syear)
if int(ref_eyear) < oeyear:
  oeyear = int(ref_eyear)
del(ref_dic,ref_syear,ref_eyear)

#######################################

# If True, remove Domain Mean of each time step
RmDomainMean = {{ RmDomainMean }}

# If True, consider EOF with unit variance
EofScaling = {{ EofScaling }}

# Conduct CBF analysis
CBF = {{ CBF }}

# Conduct conventional EOF analysis
ConvEOF = {{ ConvEOF }}

# Generate CMEC compliant json
cmec = {{ cmec }}

# Update diagnostic file if exist
update_json = {{ update_json }}

#######################################
results_dir = os.path.join(
    "${results_dir}",
    "%(output_type)",
    "variability_modes",
    "%(mip)",
    "%(exp)",
    "${case_id}",
    "%(variability_mode)",
    "%(reference_data_name)",
)
{%- endif %}

{%- if "enso" in subset %}
############################################################
#parameter setup specific for enso metrics
############################################################
mip = test_mip
exp = test_exp
realm = test_realm
realization = realm

msyear = test_start_yr
meyear = test_end_yr

osyear = ref_start_yr
oeyear = ref_end_yr

modnames = [ test_product ]

#######################################
# Model (test)
# generate land/sea mask if not exist
test_dic = json.load(open(os.path.join('${results_dir}','{}_{{sub}}_mon_catalogue.json'.format(test_data_path))))
for var in test_dic:
  model = test_dic[var]['model']
  mpath = test_dic[var]['file_path']
  mpath_lf = os.path.join('${fixed_dir}',"sftlf.{}.nc".format(model))
  tableId = test_dic[var]['tableId']
  # generate land/sea mask if not exist
  if not os.path.exists(mpath_lf) :
    print("generate land/sea mask file....")
    return_code = subprocess.call(
                    ['python', 'generate_sftlf.py',
                     var, model, mpath, mpath_lf],
                  text=False)
    if return_code != 0:
      exit("Failed to generate land/sea mask...")
  del(model,mpath,mpath_lf)
del(test_dic)

# setup template for fixed files (e.g. land/sea mask)
modpath_lf = os.path.join('${fixed_dir}',"sftlf_%(model).nc")

# construct model template
modpath = os.path.join(
      test_data_path,
      "%(mip).%(exp).%(model).%(realization)."+tableId+".%(variable)."
    + '{:04d}{:02d}-{:04d}{:02d}'.format(msyear,1,meyear,12)
    + ".nc")

# OBSERVATIONS
ref_dic = json.load(open(os.path.join('${results_dir}','{}_{{sub}}_mon_catalogue.json'.format(ref_data_path))))
# generate land/sea mask if not exist for reference
reference_data_path = {}
reference_data_lf_path = {}
for var in ref_dic:
  #orgnize obs catalog
  refname = ref_dic[var]['model']
  if refname not in reference_data_path.keys():
    reference_data_path[refname] = {}
  reference_data_path[refname][var] = {'template': ref_dic[var]['template']}

  # generate land/sea mask if not exist for reference
  refpath_lf = os.path.join('${fixed_dir}','sftlf.{}.nc'.format(refname))
  reference_data_lf_path[refname] = refpath_lf
  refpath = ref_dic[var]['file_path']
  if not os.path.exists(refpath_lf):
    print("generate land/sea mask file....")
    return_code = subprocess.call(
                    ['python', 'generate_sftlf.py',
                     var,refname,refpath,refpath_lf],
                  text=False)
    if return_code != 0:
      exit("Failed to generate land/sea mask...")

  #update time information(minimum overlap)
  ref_syear = str(ref_dic[var]['start_yymm'])[0:4]
  ref_eyear = str(ref_dic[var]['end_yymm'])[0:4]
  if int(ref_syear) > osyear:
    osyear = int(ref_syear)
  if int(ref_eyear) < oeyear:
    oeyear = int(ref_eyear)
  del(refname,refpath,refpath_lf)
del(ref_dic)

#document the observation catalogue
obs_cmor = True
obs_cmor_path = ref_data_path
obs_catalogue = 'obs_info_catalogue.json'
json.dump(reference_data_path,
          open(obs_catalogue,"w"),
          sort_keys=True,
          indent=4,
          separators=(",", ": "))
del(reference_data_path)

# METRICS COLLECTION (ENSO_perf, ENSO_tel, ENSO_proc)
# will set in main driver
# metricsCollection = ENSO_perf  # ENSO_perf, ENSO_tel, ENSO_proc

# OUTPUT
results_dir = os.path.join(
    "${results_dir}",
    "%(output_type)",
    "enso_metric",
    "%(mip)",
    "%(exp)",
    "${case_id}",
    "%(metricsCollection)",
)

json_name = "%(mip)_%(exp)_%(metricsCollection)_${case_id}_%(model)_%(realization)"

netcdf_name = json_name

{%- endif %}

EOF
{%- endif %}

################################################################

# Run PCMDI Diags
echo
echo ===== RUN PCMDI DIAGS =====
echo

# Prepare configuration file
cat > pcmdi.py << EOF
import os
import copy
import numpy
import glob
import json
import re
import sys
import time
import shapely  # noqa: F401
import cdms2
import collections
from re import split
from argparse import RawTextHelpFormatter
from shutil import copyfile
import datetime
import cdutil
import subprocess
import pcmdi_metrics

{%- if "mean_climate" in subset %}
#from pcmdi_metrics.pcmdi import PMPDriver, create_mean_climate_parser
#from pcmdi_metrics.io import StringConstructor
#from pcmdi_metrics.mean_climate.lib import calculate_climatology
#from pcmdi_metrics.mean_climate.lib.pmp_parser import PMPMetricsParser
{%- endif %}

{%- if "variability_mode" in subset %}
from argparse import RawTextHelpFormatter
from shutil import copyfile
import cdtime
import cdutil
import MV2
from genutil import StringConstructor
from pcmdi_metrics import resources
from pcmdi_metrics.variability_mode.lib import (
    AddParserArgument,
    VariabilityModeCheck,
    YearCheck,
    adjust_timeseries,
    calc_stats_save_dict,
    calcSTD,
    debug_print,
    eof_analysis_get_variance_mode,
    gain_pcs_fraction,
    gain_pseudo_pcs,
    get_domain_range,
    linear_regression_on_globe_for_teleconnection,
    plot_map,
    read_data_in,
    sort_human,
    tree,
    variability_metrics_to_json,
    write_nc_output,
)
{%- endif %}

{%- if "enso" in subset %}
from pcmdi_metrics.mjo.lib import dict_merge
from pcmdi_metrics.utils import StringConstructor, sort_human
{%- endif %}

{%- if "mean_climate" in subset %}

def calculate_climatology(start_yr,end_yr,data_file,outpath):
  #####################################
  #calculate annual cycle climatology
  #####################################
  if not os.path.exists(outpath):
    os.makedirs(outpath)
  data_dic = json.load(open(data_file))
  clim_dic = collections.OrderedDict()
  for var in data_dic.keys():
    cyms = '{:04d}-{:02d}'.format(start_yr,1)
    cyme = '{:04d}-{:02d}'.format(end_yr,12)
    if int(data_dic[var]['start_yymm']) > (start_yr*100+1):
      cyms = '{}-{}'.format(str(data_dic[var]['start_yymm'])[0:4],
                            str(data_dic[var]['start_yymm'])[4:6])
    if int(data_dic[var]['end_yymm']) < (end_yr*100+12):
      cyme = '{}-{}'.format(str(data_dic[var]['end_yymm'])[0:4],
                            str(data_dic[var]['end_yymm'])[4:6])
    infile = data_dic[var]['file_path']
    outfile = data_dic[var]['template']
    if os.path.exists(infile):
      #call pcmdi_compute_climatologies.py driver....
      return_code = subprocess.call(
                      ["pcmdi_compute_climatologies.py",
                       "--start", cyms,
                       "--end", cyme,
                       "--var", var,
                       "--infile", infile,
                       "--outpath", outpath,
                       "--outfilename", outfile],
                    text=False)
    if return_code == 0:
      print("")
      print("Sucess on mean climate diagnostics")
      print("")
    else:
      print("")
      print("Failed on mean climate diagnostics")
      exit("Command failed with return code {}".format(return_code))

    #document results info in dictionary file#
    period = "{}-{}".format(cyms.replace("-",""),cyme.replace("-",""))
    template = outfile.replace(".nc",".{}.AC.{}.nc".format(period,'${case_id}'))
    clim_dic[var] = {data_dic[var]['exp']   : data_dic[var]['model'],
                     data_dic[var]['model'] : {'template'  : template,
	                                       'period'    : period,
		                               'data_path' : outpath}
		     }
    del(template,infile,outfile,period,cyms,cyme)
  del (data_dic,outpath)

  return clim_dic

def derived_climatology(start_yr,end_yr,data_dic,outpath):
  #####################################
  #calculate annual cycle climatology
  #####################################
  derive_dic = json.load(open("derived_variable.json"))
  for var in derive_dic.keys():
    if var not in data_dic.keys():
      vv = (derive_dic[var].keys())
      infile = []
      outfile = data_dic[vv[0]]['file_path'].replace(vv[0],var)
      l_derive = True
      for k in range(len(vv)):
        if not os.path.exists(data_dic[vv[k]]['file_path']):
          l_derive = False
      if l_derive:
        for k in range(len(vv)):
          infile = data_dic[vv[k]]['file_path']
          if k == 0:
            copyfile(infile,outfile)
          else:
            return_code = subprocess.call(["ncks -A ",infile,outfile],text=False)
            if return_code != 0:
              print("")
              print("Failed on cat {} to {}".format(infile,outfile))
              exit("Command failed with return code {}".format(return_code))
          del(infile)
      if os.path.exists(outfile):
        infile = data_dic[var]['file_path']
        outfile = data_dic[var]['template']
  return clim_dic

{%- endif %}

def main ():
  short_name = '${short}'
  start_yr = int('${Y1}')
  end_yr = int('${Y2}')
  num_years = end_yr - start_yr + 1

  # Model
  # Test data path
{% if run_type == "model_vs_obs" %}
  test_data_path = 'ts'
{% elif run_type == "model_vs_model" %}
  test_data_path = 'ts_test'
{%- endif %}
  test_name = '${case}'
  short_test_name = short_name
  test_start_yr = start_yr
  test_end_yr = end_yr
  test_dir_source='{{ output }}/post/atm/{{ grid }}/cmip_ts/monthly'
  test_mip = '{{ mip }}'
  test_exp = '{{ exp }}'
  test_realm = '{{ realization }}'
  test_product = '{{ product }}'

  # Ref
{% if run_type == "model_vs_obs" %}
  # Obs
  reference_dir_source = '{{ obs_ts }}'
  ref_data_path = 'ts_ref'
  ref_start_yr = {{ ref_start_yr }}
  ref_end_yr = ref_start_yr + num_years - 1
  if (ref_end_yr <= {{ ref_final_yr }}):
    ref_end_yr = ref_end_yr
  else:
    ref_end_yr = {{ ref_final_yr }}
{% elif run_type == "model_vs_model" %}
  # Reference
  reference_dir_source = '{{ reference_data_path_ts }}'
  ref_data_path = 'ts_ref'
  ref_name = '${ref_name}'
  short_ref_name = '{{ short_ref_name }}'
  ref_start_yr = {{ ref_start_yr }}
  ref_end_yr = {{ ref_final_yr }}
  ref_mip = '{{ ref_mip }}'
  ref_exp = '{{ ref_exp }}'
  ref_realm = '{{ ref_realization }}'
  ref_product = '{{ ref_product }}'

  # Optionally, swap test and reference model
  if {{ swap_test_ref }}:
    test_data_path, ref_data_path = ref_data_path, test_data_path
    test_name, ref_name = ref_name, test_name
    short_test_name, short_ref_name = short_ref_name, short_test_name
    ref_mip, test_mip = test_mip, ref_mip
    ref_exp, test_exp = test_exp, ref_exp
    ref_realm, test_realm = test_realm, ref_realm
    ref_product, test_product = test_product, ref_product
{%- endif %}

  # Run PCMDI for diagnostics
{%- if "mean_climate" in subset %}
  print("calculate mean climate diagnostics")
  outpath = os.path.join('${results_dir}',"climo/")
  # calculate and save climatology for test
  test_data_dic = os.path.join('${results_dir}','{}_{{sub}}_mon_catalogue.json'.format(test_data_path))
  test_clim_dic = calculate_climatology(test_start_yr,test_end_yr,test_data_dic,outpath)
  # check if derived variables are needed for mean climate metrics
  # test_clim_dic = derived_climatology(test_start_yr,test_end_yr,test_clim_dic,outpath)
  # finally save the climatology dictionary files
  json.dump(test_clim_dic,
            open(os.path.join('${results_dir}','{}_{{sub}}_clim_catalogue.json'.format(test_data_path)),"w"),
            sort_keys=True,
            indent=4,
            separators=(",", ": "))
  del(test_data_dic,test_clim_dic)

  # calculate and save climatology for reference
  ref_data_dic = os.path.join('${results_dir}','{}_{{sub}}_mon_catalogue.json'.format(ref_data_path))
  ref_clim_dic = calculate_climatology(ref_start_yr,ref_end_yr,ref_data_dic,outpath)
  # check if derived variables are needed for mean climate metrics
  # ref_clim_dic = derived_climatology(ref_start_yr,ref_end_yr,ref_clim_dic,outpath)
  # finally save the climatology dictionary files
  json.dump(ref_clim_dic,
            open(os.path.join('${results_dir}','{}_{{sub}}_clim_catalogue.json'.format(ref_data_path)),"w"),
            sort_keys=True,
            indent=4,
            separators=(",", ": "))
  del(ref_data_dic,ref_clim_dic)

  #####################################################################
  # call mean_climate_driver.py to process diagnostics
  #####################################################################
  return_code = subprocess.call(
                  ['mean_climate_driver.py',
                   '-p', "parameterfile.py"],
                text=False)

  if return_code == 0:
    print("")
    print("Sucess on mean climate diagnostics")
    print("")
  else:
    print("")
    print("Failed on mean climate diagnostics")
    exit("Command failed with return code {}".format(return_code))

  # post process to reorgnize the metric data file
  #variables = [s.split("/")[-1]
  #              for s in glob.glob(
  #                  os.path.join(
  #                      '${results_dir}',
  #                      "metrics_results",
  #                      "mean_climate",
  #		  	 '{{mip}}',
  #                      '{{exp}}',
  #                      '${case_id}',
  #                      "*",
  #                  )
  #              )
  #              if os.path.isdir(s)
  #          ]
  #
  #obs_sets = list('{{ reference_sets }}'.split(","))
  #for i, var in enumerate(variables):
  #  if len(obs_sets) != len(variables):
  #    obs = obs_sets[0]
  #  else:
  #    obs = obs_sets[i]
  #  merge_json('{{mip}}', '{{exp}}', '${case_id}', var, obs,
  #              test_start_yr, test_end_yr, '${results_dir}')

{%- endif %}

{%- if "variability_mode" in subset %}
  print("calculate mode variability metrics")
{%- if subset == "variability_mode_atm" %}
  modes = list({{ atm_modes }})
{% elif subset == "variability_mode_cpl" %}
  modes = list({{ cpl_modes }})
{%- endif %}
  for variability_mode in modes:
    if variability_mode in ["NPO", "NPGO", "PSA1"]:
      eofn_obs = "2"
      eofn_mod = "2"
    elif variability_mode in ["PSA2"]:
      eofn_obs = "3"
      eofn_mod = "3"
    else:
      eofn_obs = "1"
      eofn_mod = "1"
    #####################################################################
    # call variability_modes_driver.py to process diagnostics
    #####################################################################
    print("working on {} variability metrics".format(variability_mode))
    return_code = subprocess.call(
                    ['variability_modes_driver.py',
                     '-p', "parameterfile.py",
                     '--variability_mode', variability_mode,
                     '--eofn_mod', eofn_mod,
                     '--eofn_obs', eofn_obs ],
                  text=False)
    if return_code == 0:
      print("")
      print("Sucess on {} variability diagnostics".format(variability_mode))
      print("")
    else:
      print("")
      print("Failed on {} variability diagnostics".format(variability_mode))
      exit("Command failed with return code {}".format(return_code))
{%- endif %}

{%- if "enso" in subset %}
  print("calculate enso metrics")
  groups = list({{ groups }})
  for metricsCollection in groups:
    #####################################################################
    # call enso_driver.py to process diagnostics
    #####################################################################
    return_code = subprocess.call(
                    ['enso_driver.py',
                     '-p', "parameterfile.py",
                     '--metricsCollection',metricsCollection],
                  text=False)

    if return_code == 0:
      print("")
      print("Sucess on {} diagnostics".format(metricsCollection))
      print("")
    else:
      print("")
      print("Failed on {} diagnostics".format(metricsCollection))
      exit("Command failed with return code {}".format(return_code))

    #post process and generate figures
    #print("mip, exp, MC, case_id:", '{{ mip}}', '{{ exp }}', metricsCollection, '${case_id}')
    #merge_jsons('{{ mip }}', '{{ exp}}', '${case_id}', metricsCollection, '${results_dir}')

{%- endif %}

if __name__ == "__main__":
  main()

EOF

################################
# Run diagnostics
#command="srun -n 1 python -u pcmdi.py"
command="python -u pcmdi.py"
# Run diagnostics
time ${command}
if [ $? != 0 ]; then
  cd {{ scriptDir }}
  echo 'ERROR (10)' > {{ prefix }}.status
  exit 9
fi

# Copy output to web server
echo
echo ===== COPY FILES TO WEB SERVER =====
echo

# Create top-level directory
web_dir=${www}/${case}/pcmdi_diags #/{{ sub }}
mkdir -p ${web_dir}
if [ $? != 0 ]; then
  cd {{ scriptDir }}
  echo 'ERROR (10)' > {{ prefix }}.status
  exit 10
fi

{% if machine in ['pm-cpu', 'pm-gpu'] %}
# For NERSC, make sure it is world readable
f=`realpath ${web_dir}`
while [[ $f != "/" ]]
do
  owner=`stat --format '%U' $f`
  if [ "${owner}" = "${USER}" ]; then
    chgrp e3sm $f
    chmod go+rx $f
  fi
  f=$(dirname $f)
done
{% endif %}

# Copy files
#rsync -a --delete ${results_dir} ${web_dir}/
rsync -a ${results_dir} ${web_dir}/
if [ $? != 0 ]; then
  cd {{ scriptDir }}
  echo 'ERROR (11)' > {{ prefix }}.status
  exit 11
fi

{% if machine in ['pm-cpu', 'pm-gpu'] %}
# For NERSC, change permissions of new files
pushd ${web_dir}/
chgrp -R e3sm ${results_dir}
chmod -R go+rX,go-w ${results_dir}
popd
{% endif %}

{% if machine in ['anvil', 'chrysalis'] %}
# For LCRC, change permissions of new files
pushd ${web_dir}/
chmod -R go+rX,go-w ${results_dir}
popd
{% endif %}

# Delete temporary workdir
cd ..
if [[ "${debug,,}" != "true" ]]; then
  rm -rf ${workdir}
fi

# Update status file and exit
{% raw %}
ENDTIME=$(date +%s)
ELAPSEDTIME=$(($ENDTIME - $STARTTIME))
{% endraw %}
echo ==============================================
echo "Elapsed time: $ELAPSEDTIME seconds"
echo ==============================================
rm -f {{ prefix }}.status
echo 'OK' > {{ prefix }}.status
exit 0
