#!/bin/bash
{% include 'slurm_header.sh' %}

{{ environment_commands }}

# Turn on debug output if needed
debug={{ debug }}
if [[ "${debug,,}" == "true" ]]; then
  set -x
fi

# Need this setup as otherwise can not generate diagnostics
export UCX_SHM_DEVICES=all # or not set UCX_NET_DEVICES at all

# Make sure UVCDAT doesn't prompt us about anonymous logging
export UVCDAT_ANONYMOUS_LOG=False

# Script dir
cd {{ scriptDir }}

# Get jobid
id=${SLURM_JOBID}

# Update status file
STARTTIME=$(date +%s)
echo "RUNNING ${id}" > {{ prefix }}.status

# Basic definitions
case="{{ case }}"
short="{{ short_name }}"
www="{{ www }}"
y1={{ year1 }}
y2={{ year2 }}
Y1="{{ '%04d' % (year1) }}"
Y2="{{ '%04d' % (year2) }}"
{% if run_type == "model_vs_model" %}
ref_Y1="{{ '%04d' % (ref_year1) }}"
ref_Y2="{{ '%04d' % (ref_year2) }}"
{%- endif %}
run_type="{{ run_type }}"
tag="{{ tag }}"

results_dir=${tag}_${Y1}-${Y2}

ref_name={{ ref_name }}

#info for pcmdi specific data structure
case_id=v$(date '+%Y%m%d')

# Create temporary workdir
workdir=`mktemp -d tmp.${id}.XXXX`
cd ${workdir}

# Create results directory
if [ ! -d ${results_dir} ];then
  mkdir -p ${results_dir}
fi
#directory to save land/sea mask generated by pcmdi
fixed_dir="${results_dir}/fixed"
if [ ! -d ${fixed_dir} ];then
  mkdir -p ${fixed_dir}
fi

# Prepare data files for pcmdi diagnostics, which is achieved by two steps:
# (a) convert e3sm output to cmip type, which used the "e3sm_to_cmip" function
#     available at zppy (modifications are made to process more variables and
#     3D fileds at fixed pressure levels).
# (b) locate observations in e3sm diagnostics and convert them to the pcmdi preferred
#     data format
#file to specify reference data used to derive the diagnostic metrics
cat > reference_alias.json << EOF
{% include reference_alias %}
EOF
#regions specified to derive global/regional mean metrics
cat > regions_specs.json << EOF
{% include regions_specs %}
EOF
#file include derived variables
cat > derived_variable.json << EOF
{% include derived_variable %}
EOF
#file to genereate land/sea mask data if not available
cat > generate_sftlf.py << EOF
{% include process_sftlf %}
EOF

# script for pcmdi pre-processing
cat > collect_data.py << EOF
import os
import pprint
import shlex
import requests
import subprocess
import time
import psutil
import json
import sys
import re
import glob
import errno
from shutil import copyfile
import numpy as np
import collections
import cdms2
import gc

def childCount():
    current_process = psutil.Process()
    children = current_process.children()
    return(len(children))

def combine_time_series(varibles,start_yr,end_yr,num_years,
                        mip,exp,realm,product,dir_source,outpath):

  #special case treatment (not in cmip cmor list)
  altmod_dic = {"sst"    : "ts",
                "taux"   : "tauu",
                "tauy"   : "tauv",
                "rstcre" : "SWCF",
                "rltcre" : "LWCF"}

  # list of model data dictionary
  mod_out  = collections.OrderedDict()
  var_list = []
  lstcmd0  = []
  lstcmd1  = []
  for key in varibles:
    if "_" in key or "-" in key:
      var = re.split("_|-", key)[0]
    else:
      var = key
    varin = var
    if var in ["areacella", "sftlf", "orog"]:
      fpaths = sorted(glob.glob(os.path.join(dir_source,var+"_*.nc")))
      for fpath in fpaths:
        if os.path.exists(fpath):
          output = os.path.join(outpath,"{}_fx_{}.nc".format(var,product))
          copyfile(fpath,output)
      del(fpaths)
    else:
      fpaths = sorted(glob.glob(os.path.join(dir_source,varin+"_*.nc")))
      #code below attempts to address special scenarios
      if len(fpaths) < 1 and var in altmod_dic.keys():
        varin = altmod_dic.get(var,var)
        if varin == "SWCF" or varin == "LWCF":
          dir_source1 = "/".join(dir_source.split("/")[0:-2])+"/ts/monthly/{{ts_num_years}}yr"
          fpaths = sorted(glob.glob(os.path.join(dir_source1,varin+"_*.nc")))
        else:
          fpaths = sorted(glob.glob(os.path.join(dir_source,varin+"_*.nc")))
      if len(fpaths) > 0:
        tableId = fpaths[0].split("/")[-1].split("_")[1]
        if tableId not in [ "Amon", "Lmon", "Omon", "SImon" ]:
           tableId = "Amon"

        yms = '{:04d}01'.format(start_yr)
        yme = '{:04d}12'.format(end_yr)
        fname = "{}.{}.{}.{}.{}.{}.{}-{}.nc".format(
                 mip,exp,product.replace(".","-"),realm,tableId,var,yms,yme)

        if not os.path.exists(outpath):
          os.makedirs(outpath)
        output = os.path.join(outpath,fname)
        if not os.path.exists(output):
          if var not in var_list:
            var_list.append(var)
            cmd_list = []
            cmd_list.append("ncrcat -v {} -d time,{}-01-01,{}-12-31".format(varin,yms[0:4],yme[0:4]))
            for fpath in fpaths:
              cmd_list.append(fpath)
            cmd_list.append(output)
            cdm0 = (" ".join(cmd_list))
            lstcmd0.append(cdm0)
            del(cmd_list,cdm0)
            if varin != var:
              cmd_extra = "ncrename -v {},{} {}".format(varin,var,output)
              lstcmd1.append(cmd_extra)
              del(cmd_extra)

          ############################################################
          #record the test model data information
          mod_out[var] = { "mip"        : mip,
                           "exp"        : exp,
                           "realization": realm,
                           "tableId"    : tableId,
                           "model"      : product.replace(".","-"),
                           "file_path"  : output,
                           "template"   : fname,
                           "start_yymm" : yms,
                           "end_yymm"   : yme,
                           "varin"      : varin }
      del(fpaths)
      gc.collect()
  return var_list, mod_out, lstcmd0, lstcmd1

def locate_ts_observation (variables,obs_sets,start_yr,end_yr,input_path,output_path):
  # special case treatment (inconsistent with cmip cmor vars)
  altobs_dic = { "pr"      : "PRECT",
                 "sst"     : "ts",
                 "sfcWind" : "si10",
                 "taux"    : "tauu",
                 "tauy"    : "tauv",
                 "rltcre"  : "toa_cre_lw_mon",
                 "rstcre"  : "toa_cre_sw_mon",
                 "rtmt"    : "toa_net_all_mon"}
  # find observational data avaiable in e3sm_diags
  mip = "obs"
  realization = "00"
  tableId = "Amon"
  obs_sets = list('{{ reference_sets }}'.split(","))
  obs_dic = json.load(open(os.path.join('.','reference_alias.json')))
  obs_out = collections.OrderedDict()

  var_list = []
  lstcmd0  = []
  lstcmd1  = []
  for i,key in enumerate(variables):
    if "_" in key or "-" in key:
      var = key.split("_|-", var)[0]
    else:
      var = key

    if len(obs_sets) != len(variables):
      option = obs_sets[0]
    else:
      option = obs_sets[i]

    if "default" in obs_sets or "alternate" in obs_sets:
      obstag = obs_dic[var][option]
    else:
      inv_map = {v: k for k, v in obs_dic[var].items()}
      if len(obs_sets) != len(variables):
        obstag = obs_sets[0]
      else:
        obstag = obs_sets[i]
      option = inv_map[obstag]
      del(inv_map)

    varin = var
    if "ceres_ebaf" in obstag:
      fpaths = sorted(glob.glob(os.path.join(input_path,
                      obstag.replace('ceres_ebaf','ceres_ebaf*'),
                      varin+"_*.nc")))
      if len(fpaths) < 1 and var in altobs_dic.keys():
        varin = altobs_dic.get(var,var)
        fpaths = sorted(glob.glob(os.path.join(input_path,
                      obstag.replace('ceres_ebaf','ceres_ebaf*'),
                      varin+"_*.nc")))
    else:
      fpaths = sorted(glob.glob(os.path.join(input_path,obstag,var+"_*.nc")))
      if len(fpaths) < 1 and var in altobs_dic.keys():
        varin = altobs_dic.get(var,var)
        fpaths = sorted(glob.glob(os.path.join(input_path,obstag,varin+"_*.nc")))

    if len(fpaths) > 0 and os.path.exists(fpaths[0]):
      template = fpaths[0].split("/")[-1]
      obsname = fpaths[0].split("/")[-2]
      fyms = template.split("_")[-2][0:6]
      fyme = template.split("_")[-1][0:6]
      yms = '{:04d}{:02d}'.format(start_yr,1)
      yme = '{:04d}{:02d}'.format(end_yr,12)
      if int(yms) > int(fyms):
        yms = fyms
      if int(yme) < int(fyme):
        yme = fyme
      del(template,fyms,fyme)

      #rename file following cmip-like convention
      if not os.path.exists(output_path):
        os.makedirs(output_path)
      fname = "{}.{}.{}.{}.{}.{}.{}-{}.nc".format(
               mip,option,obsname.replace(".","-"),realization,tableId,var,yms,yme)
      output = os.path.join(output_path,fname)

      if not os.path.exists(output):
        #cmd0 = "cp {} {}".format(fpaths[0],output)
        #cmd0 = "ncap2 -O -s '{}' {} {}".format(
        #        '@units="hours since 1850-01-01 00:00:00";time=udunits(time,@units);time@units=@units',
        #fpaths[0],output)
        cmd0 = "ncrcat -v {} -d time,{}-01-01,{}-12-31 {} {}".format(
                       varin,yms[0:4],yme[0:4],fpaths[0],output)
        lstcmd0.append(cmd0)
        del(cmd0)
        if var != varin:
          cmd_extra = "ncrename -v {},{} {}".format(varin,var,output)
          lstcmd1.append(cmd_extra)
          del(cmd_extra)

      #record the observation information
      obs_out[var] = { "mip"         : mip,
                       "exp"         : option,
                       "realization" : realization,
                       "tableId"     : tableId,
                       "model"       : obsname,
                       "file_path"   : output,
                       "template"    : fname,
                       "start_yymm"  : yms,
                       "end_yymm"    : yme,
                       "varin"       : varin}

      var_list.append(var)
      del(fname,output)
      gc.collect()
    else :
      print("warning: reference data not found for", var)

  return var_list, obs_out, lstcmd0, lstcmd1

def main():
  #basic information
  short_name = '${short}'
  start_yr = int('${Y1}')
  end_yr = int('${Y2}')
  num_years = end_yr - start_yr + 1

  # Model
  # Test data directory
{% if run_type == "model_vs_obs" %}
  test_data_dir = 'ts'
{% elif run_type == "model_vs_model" %}
  test_data_dir = 'ts_test'
{%- endif %}
  test_name = '${case}'
  short_test_name = short_name
  test_start_yr = start_yr
  test_end_yr = end_yr
  test_dir_source='{{ output }}/post/atm/{{ grid }}/cmip_ts/monthly'

  #info for pcmdi data structure
  test_mip = '{{ mip }}'
  test_exp = '{{ exp }}'
  test_realm = '{{ realization }}'
  test_product = '{{ product }}'

  #Ref
{% if run_type == "model_vs_obs" %}
  # Obs
  reference_dir_source = '{{ obs_ts }}'
  ref_data_dir = 'ts_ref'
  ref_start_yr = {{ ref_start_yr }}
  ref_end_yr = ref_start_yr + num_years - 1
  if (ref_end_yr <= {{ ref_final_yr }}):
    ref_end_yr = ref_end_yr
  else:
    ref_end_yr = {{ ref_final_yr }}
{% elif run_type == "model_vs_model" %}
  # Reference
  reference_dir_source = '{{ reference_data_path_ts }}'
  ref_data_dir = 'ts_ref'
  ref_name = '${ref_name}'
  short_ref_name = '{{ short_ref_name }}'
  ref_start_yr = {{ ref_start_yr }}
  ref_end_yr = {{ ref_final_yr }}
  #info for pcmdi data structure
  ref_mip = '{{ ref_mip }}'
  ref_exp = '{{ ref_exp }}'
  ref_realm = '{{ ref_realization }}'
  ref_product = '{{ ref_product }}'

  # Optionally, swap test and reference model
  if {{ swap_test_ref }}:
    test_data_dir, ref_data_dir = ref_data_dir, test_data_dir
    test_name, ref_name = ref_name, test_name
    short_test_name, short_ref_name = short_ref_name, short_test_name
    ref_mip, test_mip = test_mip, ref_mip
    ref_exp, test_exp = test_exp, ref_exp
    ref_realm, test_realm = test_realm, ref_realm
    ref_product, test_product = test_product, ref_product
{%- endif %}

  ################################################################
  # process test model data for comparision
  ################################################################
  print("process test model data for comparision")
  #variable list in configuration file
  variables = list("{{ vars }}".split(","))
  cmor_vars, test_data_dic, test_cmd0, test_cmd1 = \
           combine_time_series(
                               variables, test_start_yr,test_end_yr,
                               int({{ts_num_years}}), test_mip,
                               test_exp, test_realm, test_product,
                               test_dir_source, test_data_dir
                              )

  # Save test model data information required for next step
  json.dump(test_data_dic,
	    open(os.path.join('${results_dir}',
                              '{}_{{sub}}_mon_catalogue.json'.format(test_data_dir)), "w"),
            sort_keys=True,
            indent=4,
            separators=(",", ": "))
  del(test_data_dic,variables)
  print("# of cmorized model variables: ", len(cmor_vars))

  #finally process the data in parallel
  print("Number of jobs starting is ", str(len(test_cmd0)))
  for i,p in enumerate(test_cmd0):
    procs = subprocess.Popen([p], shell=True)
    print('running %s' % (str(p)))
    while (childCount() > {{num_workers}}):
      time.sleep(0.25)
      procs.communicate() # this will get the exit code
    else:
      if (i == len(test_cmd0)-1 ):
        procs.communicate()
        break

  #second loop when rename is needed
  if len(test_cmd1) > 0:
    print("Number of jobs starting is ", str(len(test_cmd1)))
    for i,p in enumerate(test_cmd1):
      procs = subprocess.Popen([p], shell=True)
      print('running %s' % (str(p)))
      while (childCount() > {{num_workers}} ):
        time.sleep(0.25)
        procs.communicate() # this will get the exit code
      else:
        if (i == len(test_cmd1)-1 ):
          procs.communicate()
          break
  del(test_cmd0,test_cmd1)

  #set a delay to avoid delay in writing process
  time.sleep(1)
  print("done submitting")

  ################################################################
  # process reference data for comparison
  ################################################################
  print("process reference obs/model data for comparision")
{% if run_type == "model_vs_obs" %}
  obs_sets = list('{{ reference_sets }}'.split(","))
  refr_vars, obs_data_dic, obs_cmd0, obs_cmd1 = \
	locate_ts_observation (
                               cmor_vars,obs_sets,
                               ref_start_yr,ref_end_yr,
                               reference_dir_source,
                               ref_data_dir
			       )

  # Save observational information required for next step
  json.dump(obs_data_dic,
	    open(os.path.join('${results_dir}','{}_{{sub}}_mon_catalogue.json'.format(ref_data_dir)),"w"),
            sort_keys=True,
            indent=4,
            separators=(",", ": "))
  del(obs_data_dic,obs_sets)
  print("# of variables with observations: ", len(refr_vars))
  del(refr_vars,cmor_vars)

  #finally process the data in parallel
  print("Number of jobs starting is ", str(len(obs_cmd0)))
  for i,p in enumerate(obs_cmd0):
    procs = subprocess.Popen([p], shell=True)
    print('running %s' % (str(p)))
    while (childCount() > {{num_workers}}):
      time.sleep(0.25)
      procs.communicate() # this will get the exit code
    else:
      if (i == len(obs_cmd0)-1 ):
        procs.communicate()
        break

  #second loop when rename is needed
  if len(obs_cmd1) > 0:
    print("Number of jobs starting is ", str(len(obs_cmd1)))
    for i,p in enumerate(obs_cmd1):
      procs = subprocess.Popen([p], shell=True)
      print('running %s' % (str(p)))
      while (childCount() > {{num_workers}}):
        time.sleep(0.25)
        procs.communicate() # this will get the exit code
      else:
        if (i == len(obs_cmd1)-1 ):
          procs.communicate()
          break

  del(obs_cmd0,obs_cmd1)

  #set a delay to avoid delay in writing process
  time.sleep(1)
  print("done submitting")

{% elif run_type == "model_vs_model" %}
  #variable list in configuration file
  variables = list("{{ vars }}".split(","))
  refr_vars, refr_data_dic, refr_cmd0, refr_cmd1 = \
           combine_time_series(
                               variables, ref_start_yr,ref_end_yr,
                               int({{ts_num_years_ref}}), ref_mip,
                               ref_exp, ref_realm, ref_product,
                               ref_dir_source, ref_data_dir
                              )

  # Save reference information required for next step
  json.dump(ref_data_dic,
	    open(os.path.join('${results_dir}','{}_{{sub}}_mon_catalogue.json'.format(ref_data_dir)),"w"),
            sort_keys=True,
            indent=4,
            separators=(",", ": "))
  del(ref_data_dic,variables)
  print("# of variables with observations: ", len(refr_vars))
  del(refr_vars,cmor_vars)

  #finally process the data in parallel
  print("Number of jobs starting is ", str(len(refr_cmd0)))
  for i,p in enumerate(refr_cmd0):
    procs = subprocess.Popen([p], shell=True)
    print('running %s' % (str(p)))
    while (childCount() > {{num_workers}}):
      time.sleep(0.25)
      procs.communicate() # this will get the exit code
    else:
      if (i == len(refr_cmd0)-1 ):
        procs.communicate()
        break

  if len(refr_cmd1) > 0:
    print("Number of jobs starting is ", str(len(refr_cmd1)))
    for i,p in enumerate(refr_cmd1):
      procs = subprocess.Popen([p], shell=True)
      print('running %s' % (str(p)))
      while (childCount() > {{num_workers}}):
        time.sleep(0.25)
        procs.communicate() # this will get the exit code
      else:
        if (i == len(refr_cmd1)-1 ):
          procs.communicate()
          break
  del(refr_cmd0,refr_cmd1)

  #set a delay to avoid delay in writing process
  time.sleep(1)
  print("done submitting")

{%- endif %}

if __name__ == "__main__":
  main()

EOF

################################
# Pcmdi pre-processing to link
# required data to work directory
command="python -u collect_data.py"
time ${command}
if [ $? != 0 ]; then
  cd {{ scriptDir }}
  echo 'ERROR (9)' > {{ prefix }}.status
  exit 9
fi

################################################################
# generate input parameter for pcmdi metrics driver
{%- if ("mean_climate" in sets) or ("variability_mode" in sets) or ("enso" in sets) %}
cat > parameterfile.py << EOF
import os
import sys
import cdutil
import datetime
import json
import subprocess

#basic information
short_name = '${short}'
start_yr = int('${Y1}')
end_yr = int('${Y2}')
num_years = end_yr - start_yr + 1

# Model
# Test data path
{% if run_type == "model_vs_obs" %}
test_data_dir = 'ts'
{% elif run_type == "model_vs_model" %}
test_data_dir = 'ts_test'
{%- endif %}
test_name = '${case}'
short_test_name = short_name
test_start_yr = start_yr
test_end_yr = end_yr
test_dir_source='{{ output }}/post/atm/{{ grid }}/cmip_ts/monthly'
test_mip = '{{ mip }}'
test_exp = '{{ exp }}'
test_realm = '{{ realization }}'
test_product = '{{ product }}'

# Ref
{% if run_type == "model_vs_obs" %}
# Obs
reference_dir_source = '{{ obs_ts }}'
ref_data_dir = 'ts_ref'
ref_start_yr = {{ ref_start_yr }}
ref_end_yr = ref_start_yr + num_years - 1
if (ref_end_yr <= {{ ref_final_yr }}):
  ref_end_yr = ref_end_yr
else:
  ref_end_yr = {{ ref_final_yr }}
{% elif run_type == "model_vs_model" %}
# Reference
reference_dir_source = '{{ reference_data_path_ts }}'
ref_data_dir = 'ts_ref'
ref_name = '${ref_name}'
short_ref_name = '{{ short_ref_name }}'
ref_start_yr = {{ ref_start_yr }}
ref_end_yr = {{ ref_final_yr }}
ref_mip = '{{ ref_mip }}'
ref_exp = '{{ ref_exp }}'
ref_realm = '{{ ref_realization }}'
ref_product = '{{ ref_product }}'
# Optionally, swap test and reference model
if {{ swap_test_ref }}:
  test_data_dir, ref_data_dir = ref_data_dir, test_data_dir
  test_name, ref_name = ref_name, test_name
  short_test_name, short_ref_name = short_ref_name, short_test_name
  ref_mip, test_mip = test_mip, ref_mip
  ref_exp, test_exp = test_exp, ref_exp
  ref_realm, test_realm = test_realm, ref_realm
  ref_product, test_product = test_product, ref_product
{%- endif %}

# shared options
case_id = '${case_id}'

# Record NetCDF output
nc_out_obs = {{ nc_out_obs }}
nc_out = {{ nc_out }}
if nc_out:
  ext = ".nc"
else:
  ext = ".xml"

user_notes = 'Provenance and results'

num_workers = {{ num_workers }}
multiprocessing = {{ multiprocessing }}
if multiprocessing:
  parallel = True
else:
  parallel = False

debug = {{ pmp_debug }}

# Generate plots
plot = {{ plot }}
plot_obs = {{ plot_obs }} # optional

# Additional settings
run_type = '{{ run_type }}'
diff_title = '{{ diff_title }}'
output_format = {{ output_format }}
output_format_subplot = {{ output_format_subplot }}

{%- if "mean_climate" in subset %}
#############################################################
#parameter setup specific for mean climate metrics
#############################################################
mip = test_mip
exp = test_exp
realm = test_realm
realization = realm

modver = '${case_id}'

# Generate CMEC compliant json
cmec = {{ cmec }}

# SIMULATION PARAMETER
period = "{:04d}{:02d}-{:04d}{:02d}".format(test_start_yr,1,test_end_yr,12)

test_data_set = [ test_product ]

# INTERPOLATION OPTIONS
target_grid = '{{ target_grid }}'  # OPTIONS: '2.5x2.5' or an actual cdms2 grid object
targetGrid = target_grid
target_grid_string = '{{ target_grid_string }}'
regrid_tool = '{{ regrid_tool }}' # OPTIONS: 'regrid2','esmf'
regrid_method = '{{ regrid_method }}' # OPTIONS: 'linear','conservative', only if tool is esmf
regrid_tool_ocn = '{{ regrid_tool_ocn }}' # OPTIONS: "regrid2","esmf"
regrid_method_ocn = ( '{{ regrid_method_ocn }}' )  # OPTIONS: 'linear','conservative', only if tool is esmf

# SAVE INTERPOLATED MODEL CLIMATOLOGIES ?
save_test_clims = {{ save_test_clims }}

# CUSTOMIZE REGIONS VALUES NAMES
regions_values = {"land":100.,"ocean":0.}

#defined regions
regions_specs = json.load(open(os.path.join(".",'regions_specs.json')))

#region specified for each variable
regions =json.load(open(os.path.join('${results_dir}','var_region_{{sub}}_catalogue.json')))

#######################################
# DATA LOCATION: MODELS, OBS AND METRICS OUTPUT
# ---------------------------------------------
# Templates for model climatology files
test_data_path = os.path.join(
  "${results_dir}",
  "climo")
test_dic = json.load(open(os.path.join('${results_dir}','{}_{{sub}}_clim_catalogue.json'.format(test_data_dir))))
template = test_dic['ts'][test_product]['template']
filename_template = template.replace('ts',"%(variable)").replace(test_product,"%(model)")
del(test_dic)

#######################################
# ROOT PATH FOR OBSERVATIONS
reference_data_set = list('{{ reference_sets }}'.split(","))
reference_data_path = os.path.join('${results_dir}',"climo")
observation_file = os.path.join('${results_dir}','{}_{{sub}}_clim_catalogue.json'.format(ref_data_dir))
custom_observations  = os.path.abspath(observation_file)
if not os.path.exists(custom_observations):
  sys.exit("ERROR: observation climatology file is missing....")

#######################################
# DIRECTORY AND FILENAME FOR OUTPUTING METRICS RESULTS
metrics_in_single_file = 'n'  #  'y' or 'n'
metrics_output_path = os.path.join(
    "${results_dir}",
    "metrics_results",
    "mean_climate",
    mip,
    exp,
    "%(case_id)"
)  # All SAME FILE
############################################################
# DIRECTORY WHERE TO PUT INTERPOLATED MODELS' CLIMATOLOGIES
diagnostics_output_path= os.path.join(
    "${results_dir}",
    "diagnostic_results",
    "mean_climate",
    mip,
    exp,
    "%(case_id)"
)

###########################################
# Templates for MODEL land/sea mask (sftlf)
# depracated in new version of pcmdi
#############################################
generate_sftlf = {{ generate_sftlf }}
os.path.join('${fixed_dir}',"sftlf_%(model).nc")
test_clims_interpolated_output = diagnostics_output_path

{%- endif %}

{%- if "variability_mode" in subset  %}
############################################################
#parameter setup specific for mode variability metrics
############################################################
mip = test_mip
exp = test_exp
realm = test_realm
realization = realm

modnames = [ test_product ]

msyear    = test_start_yr
meyear    = test_end_yr
osyear    = ref_start_yr
oeyear    = ref_end_yr

seasons   = list('{{ seasons }}'.split(","))
frequency = '{{ frequency }}'

#from configuration file
varOBS = '{{vars}}'
varModel = '{{vars}}'
ObsUnitsAdjust = {{ ObsUnitsAdjust }}
ModUnitsAdjust = {{ ModUnitsAdjust }}

# If True, maskout land region thus consider only over ocean
landmask = {{ landmask }}

#open dictional file to locate model and reference files
test_dic = json.load(open(os.path.join('${results_dir}','{}_{{sub}}_mon_catalogue.json'.format(test_data_dir))))
modpath = test_dic[varModel]['file_path']
model = test_dic[varModel]['model']
if model != test_product:
  print("warning: model {} in dataset differ from user setup {}".format(model,test_product))
  print("warning: use model in datasets to continue....")
  modnames = [model]
del (test_dic)

#setup template for fixed files (e.g. land/sea mask)
modpath_lf = os.path.join('${fixed_dir}',"sftlf_%(model).nc")

#open dictional file to locate reference data
ref_dic = json.load(open(os.path.join('${results_dir}',
                                      '{}_{{sub}}_mon_catalogue.json'.format(ref_data_dir))))
reference_data_name = ref_dic[varOBS]['model']
reference_data_path = ref_dic[varOBS]['file_path']

#update time for observation if different
ref_syear = str(ref_dic[varOBS]['start_yymm'])[0:4]
ref_eyear = str(ref_dic[varOBS]['end_yymm'])[0:4]
if int(ref_syear) > osyear:
  osyear = int(ref_syear)
if int(ref_eyear) < oeyear:
  oeyear = int(ref_eyear)
del(ref_dic,ref_syear,ref_eyear)

#######################################

# If True, remove Domain Mean of each time step
RmDomainMean = {{ RmDomainMean }}

# If True, consider EOF with unit variance
EofScaling = {{ EofScaling }}

# Conduct CBF analysis
CBF = {{ CBF }}

# Conduct conventional EOF analysis
ConvEOF = {{ ConvEOF }}

# Generate CMEC compliant json
cmec = {{ cmec }}

# Update diagnostic file if exist
update_json = {{ update_json }}

#######################################
results_dir = os.path.join(
    "${results_dir}",
    "%(output_type)",
    "variability_modes",
    "%(mip)",
    "%(exp)",
    "${case_id}",
    "%(variability_mode)",
    "%(reference_data_name)",
)
{%- endif %}

{%- if "enso" in subset %}
############################################################
#parameter setup specific for enso metrics
############################################################
mip = test_mip
exp = test_exp
realm = test_realm
realization = realm

msyear = test_start_yr
meyear = test_end_yr

osyear = ref_start_yr
oeyear = ref_end_yr

modnames = [ test_product ]

#######################################
# Model (test)
# setup template for fixed files (e.g. land/sea mask)
modpath_lf = os.path.join('${fixed_dir}',"sftlf_%(model).nc")
# construct model template
test_dic = json.load(open(os.path.join('${results_dir}','{}_{{sub}}_mon_catalogue.json'.format(test_data_dir))))
vv0 = list(test_dic.keys())[0]
tableId = test_dic[vv0]['tableId']
modpath = os.path.join(
      test_data_dir,
      "%(mip).%(exp).%(model).%(realization)."+tableId+".%(variable)."
    + '{:04d}{:02d}-{:04d}{:02d}'.format(msyear,1,meyear,12)
    + ".nc")
del(test_dic,vv0)

# OBSERVATIONS
reference_data_path = {}
reference_data_lf_path = {}
#orgnize obs catalog
ref_dic = json.load(open(os.path.join('${results_dir}','{}_{{sub}}_mon_catalogue.json'.format(ref_data_dir))))
for var in ref_dic:
  refname = ref_dic[var]['model']
  if refname not in reference_data_path.keys():
    reference_data_path[refname] = {}
  reference_data_path[refname][var] = {'template': ref_dic[var]['template']}
  #land/sea mask
  reference_data_lf_path[refname] = os.path.join('${fixed_dir}','sftlf.{}.nc'.format(refname))
  #update time information(minimum overlap)
  ref_syear = str(ref_dic[var]['start_yymm'])[0:4]
  ref_eyear = str(ref_dic[var]['end_yymm'])[0:4]
  if int(ref_syear) > osyear:
    osyear = int(ref_syear)
  if int(ref_eyear) < oeyear:
    oeyear = int(ref_eyear)
  del(refname)
del(ref_dic)

#document the observation catalogue
obs_cmor = True
obs_cmor_path = ref_data_dir
obs_catalogue = 'obs_info_catalogue.json'
json.dump(reference_data_path,
          open(obs_catalogue,"w"),
          sort_keys=True,
          indent=4,
          separators=(",", ": "))
del(reference_data_path)

# METRICS COLLECTION (ENSO_perf, ENSO_tel, ENSO_proc)
# will set in main driver
# metricsCollection = ENSO_perf  # ENSO_perf, ENSO_tel, ENSO_proc

# OUTPUT
results_dir = os.path.join(
    "${results_dir}",
    "%(output_type)",
    "enso_metric",
    "%(mip)",
    "%(exp)",
    "${case_id}",
    "%(metricsCollection)",
)

json_name = "%(mip)_%(exp)_%(metricsCollection)_${case_id}_%(model)_%(realization)"

netcdf_name = json_name

{%- endif %}

EOF
{%- endif %}

################################################################

# Run PCMDI Diags
echo
echo ===== RUN PCMDI DIAGS =====
echo

# Prepare configuration file
cat > pcmdi.py << EOF
import os
import numpy
import glob
import json
import re
import sys
import cdms2
import collections
import datetime
import cdutil
import subprocess
import time
import psutil
import cdtime
import MV2
import pcmdi_metrics
from pcmdi_metrics.utils import StringConstructor, sort_human
from argparse import RawTextHelpFormatter
from shutil import copyfile
from re import split

def childCount():
    current_process = psutil.Process()
    children = current_process.children()
    return(len(children))

def merge_json(var,obs,metricdir,metricname,pmprdir):
    json_file_dir_template = os.path.join(
        metricdir,
        metricname,
	{{mip}},
	{{exp}},
        '${case_id}',
        "%(var)"
    )
    json_file_dir_template = StringConstructor(json_file_dir_template)
    json_file_dir = os.path.join(
        pmprdir,
        json_file_dir_template(mip=mip, exp=exp, case_id=case_id, var=var),
    )

    print("json_file_dir:", json_file_dir)

    json_file_template = "%(model)_%(var)_*_%(obs).json"
    json_file_template = StringConstructor(json_file_template)

    # Search for individual JSONs
    json_files = sorted(
        glob.glob(
            os.path.join(
                json_file_dir,
                json_file_template(
                    # mip=mip,
                    # exp=exp,
                    var=var,
                    model="*",
                    # run="*",
                    obs=obs,
                ),
            )
        )
    )

    print("json_files:", json_files)

    # Remove diveDown JSONs and previously generated merged JSONs if included
    json_files_revised = copy.copy(json_files)
    for j, json_file in enumerate(json_files):
        filename_component = json_file.split("/")[-1].split(".")[0].split("_")
        if "allModels" in filename_component:
            json_files_revised.remove(json_file)
        elif "allRuns" in filename_component:
            json_files_revised.remove(json_file)

    # Load individual JSON and merge to one big dictionary
    for j, json_file in enumerate(json_files_revised):
        print(j, json_file)
        f = open(json_file)
        dict_tmp = json.loads(f.read())
        if j == 0:
            dict_final = dict_tmp.copy()
        else:
            dict_merge(dict_final, dict_tmp)
        f.close()

    # Dump final dictionary to JSON
    final_json_filename = StringConstructor("%(var)_%(mip)_%(exp)_%(case_id).json")(
        var=var, mip=mip, exp=exp, case_id=case_id
    )
    final_json_file = os.path.join(json_file_dir, "..", final_json_filename)

    with open(final_json_file, "w") as fp:
        json.dump(dict_final, fp, sort_keys=True, indent=4)

    return

{%- if "mean_climate" in subset %}

def calculate_climatology(start_yr,end_yr,data_file,outpath):
  #####################################
  #calculate annual cycle climatology
  #####################################
  if not os.path.exists(outpath):
    os.makedirs(outpath)
  data_dic = json.load(open(data_file))
  clim_dic = collections.OrderedDict()
  lstcmd = []
  for var in data_dic.keys():
    cyms = '{:04d}-{:02d}'.format(start_yr,1)
    cyme = '{:04d}-{:02d}'.format(end_yr,12)
    if int(data_dic[var]['start_yymm']) > (start_yr*100+1):
      cyms = '{}-{}'.format(str(data_dic[var]['start_yymm'])[0:4],
                            str(data_dic[var]['start_yymm'])[4:6])
    if int(data_dic[var]['end_yymm']) < (end_yr*100+12):
      cyme = '{}-{}'.format(str(data_dic[var]['end_yymm'])[0:4],
                            str(data_dic[var]['end_yymm'])[4:6])
    infile = data_dic[var]['file_path']
    outfile = data_dic[var]['template']
    if os.path.exists(infile):
      cmd0 = (" ".join(["pcmdi_compute_climatologies.py",
                        "--start", cyms,
                        "--end", cyme,
                        "--var", var,
                        "--infile", infile,
                        "--outpath", outpath,
                        "--outfilename", outfile ]))
      lstcmd.append(cmd0)
      del(cmd0)

      #document results info in dictionary file#
      period = "{}-{}".format(cyms.replace("-",""),cyme.replace("-",""))
      template = outfile.replace(".nc",".{}.AC.{}.nc".format(period,'${case_id}'))
      clim_dic[var] = {data_dic[var]['exp']   : data_dic[var]['model'],
                       data_dic[var]['model'] : {'template'  : template,
                                                 'period'    : period,
                                                 'data_path' : outpath}}

  return clim_dic,lstcmd

def calculate_derived_variable(var,data_dic,outpath):
  ####################################################
  #this function is used to calculate a quantity given
  #the data documented in the data_dic passed by user
  #derived_variable.json is a file documen the rules to
  #calculate the required diagnostic variables
  #####################################################
  derive_dic = json.load(open("derived_variable.json"))
  vsublist = []
  operator = []
  for vv in derive_dic[var]:
    vsublist.append(vv)
    operator.append(derive_dic[var][vv])
  #now search data file and process
  l_derive = True
  for i,vv in enumerate(vsublist):
    infile = data_dic[vv]['data_path']
    if i == 0:
     outfile = infile.replace(vv,var)
    if (not os.path.exists(infile)) or (os.path.exists(outfile)):
      l_derive = False

  if l_derive:
    for i,vv in enumerate(derive_dic[var].keys()):
      infile = data_dic[vv]['data_path']
      f = cdms2.open(infile)
      if i == 0:
        d = f(vv) * operator[i]
      else:
        d = d + f(vv) * operator[i]
      f.close()
      del(infile)
    f = cdms2.open(outfile,'w')
    f.write(d)
    f.close()
    del(d,outfile,f)
    outdic = {'template'  : outfile.split("/")[-1],
              'data_path' : outfile}
  del(derive_dic,vsublist,operator)

  return outdic, outfile

{%- endif %}

def main ():
  short_name = '${short}'
  start_yr = int('${Y1}')
  end_yr = int('${Y2}')
  num_years = end_yr - start_yr + 1

  # Model
  # Test data directory
{% if run_type == "model_vs_obs" %}
  test_data_dir = 'ts'
{% elif run_type == "model_vs_model" %}
  test_data_dir = 'ts_test'
{%- endif %}
  test_name = '${case}'
  short_test_name = short_name
  test_start_yr = start_yr
  test_end_yr = end_yr
  test_dir_source='{{ output }}/post/atm/{{ grid }}/cmip_ts/monthly'
  test_mip = '{{ mip }}'
  test_exp = '{{ exp }}'
  test_realm = '{{ realization }}'
  test_product = '{{ product }}'

  # Ref
{% if run_type == "model_vs_obs" %}
  # Obs
  reference_dir_source = '{{ obs_ts }}'
  ref_data_dir = 'ts_ref'
  ref_start_yr = {{ ref_start_yr }}
  ref_end_yr = ref_start_yr + num_years - 1
  if (ref_end_yr <= {{ ref_final_yr }}):
    ref_end_yr = ref_end_yr
  else:
    ref_end_yr = {{ ref_final_yr }}
{% elif run_type == "model_vs_model" %}
  # Reference
  reference_dir_source = '{{ reference_data_path_ts }}'
  ref_data_dir = 'ts_ref'
  ref_name = '${ref_name}'
  short_ref_name = '{{ short_ref_name }}'
  ref_start_yr = {{ ref_start_yr }}
  ref_end_yr = {{ ref_final_yr }}
  ref_mip = '{{ ref_mip }}'
  ref_exp = '{{ ref_exp }}'
  ref_realm = '{{ ref_realization }}'
  ref_product = '{{ ref_product }}'

  # Optionally, swap test and reference model
  if {{ swap_test_ref }}:
    test_data_dir, ref_data_dir = ref_data_dir, test_data_dir
    test_name, ref_name = ref_name, test_name
    short_test_name, short_ref_name = short_ref_name, short_test_name
    ref_mip, test_mip = test_mip, ref_mip
    ref_exp, test_exp = test_exp, ref_exp
    ref_realm, test_realm = test_realm, ref_realm
    ref_product, test_product = test_product, ref_product
{%- endif %}

  ################################################################################
  # land/sea mask is needed in PCMDI diagnostics, check and generate it here as
  # these data are not always available for model or observations
  ################################################################################
  # Model
  test_dic = json.load(open(os.path.join('${results_dir}','{}_{{sub}}_mon_catalogue.json'.format(test_data_dir))))
  for var in test_dic:
    model = test_dic[var]['model']
    mpath = test_dic[var]['file_path']
    mpath_lf = os.path.join('${fixed_dir}',"sftlf.{}.nc".format(model))
    # generate land/sea mask if not exist
    if not os.path.exists(mpath_lf) :
      print("generate land/sea mask file....")
      return_code = subprocess.call(
                      ['python', 'generate_sftlf.py',
                       var, model, mpath, mpath_lf],
                    text=False)
      if return_code != 0:
        exit("Failed to generate land/sea mask...")
    del(model,mpath,mpath_lf)
  del(test_dic)
  # Reference
  ref_dic = json.load(open(os.path.join('${results_dir}','{}_{{sub}}_mon_catalogue.json'.format(ref_data_dir))))
  for var in ref_dic:
    refname = ref_dic[var]['model']
    refpath_lf = os.path.join('${fixed_dir}','sftlf.{}.nc'.format(refname))
    refpath = ref_dic[var]['file_path']
    if not os.path.exists(refpath_lf):
      print("generate land/sea mask file....")
      return_code = subprocess.call(
                      ['python', 'generate_sftlf.py',
                       var,refname,refpath,refpath_lf],
                    text=False)
      if return_code != 0:
        exit("Failed to generate land/sea mask...")
    del(refname,refpath,refpath_lf)
  del(ref_dic)

  # Run PCMDI for diagnostics
{%- if "mean_climate" in subset %}
  print("calculate mean climate diagnostics")
  #####################################################################
  # calculate test model climatology
  #####################################################################
  outpath = os.path.join('${results_dir}',"climo/")
  test_data_dic = os.path.join('${results_dir}','{}_{{sub}}_mon_catalogue.json'.format(test_data_dir))
  test_clim_dic, test_cmd = calculate_climatology(test_start_yr,test_end_yr,test_data_dic,outpath)
  #save the climatology dictionary files
  json.dump(test_clim_dic,
            open(os.path.join('${results_dir}','{}_{{sub}}_clim_catalogue.json'.format(test_data_dir)),"w"),
            sort_keys=True,
            indent=4,
            separators=(",", ": "))
  #finally process the data in parallel
  print("Number of jobs starting is ", str(len(test_cmd)))
  for i,p in enumerate(test_cmd):
    procs = subprocess.Popen([p], shell=True)
    print('running %s' % (str(p)))
    while (childCount() > {{num_workers}}):
      time.sleep(0.25)
      procs.communicate() # this will get the exit code
    else:
      if (i == len(test_cmd)-1):
        procs.communicate()
        break
  del(test_data_dic,test_clim_dic,test_cmd)

  # add a delay to ensure the writing process fully done
  time.sleep(1)
  print("done submitting")

  #####################################################################
  # calculate reference climatology
  #####################################################################
  ref_data_dic = os.path.join('${results_dir}','{}_{{sub}}_mon_catalogue.json'.format(ref_data_dir))
  ref_clim_dic, ref_cmd = calculate_climatology(ref_start_yr,ref_end_yr,ref_data_dic,outpath)
  #save the climatology dictionary files
  json.dump(ref_clim_dic,
            open(os.path.join('${results_dir}','{}_{{sub}}_clim_catalogue.json'.format(ref_data_dir)),"w"),
            sort_keys=True,
            indent=4,
            separators=(",", ": "))
  #finally process the data in parallel
  print("Number of jobs starting is ", str(len(ref_cmd)))
  for i,p in enumerate(ref_cmd):
    procs = subprocess.Popen([p], shell=True)
    print('running %s' % (str(p)))
    while (childCount() > {{num_workers}}):
      time.sleep(0.25)
      procs.communicate() # this will get the exit code
    else:
      if (i == len(ref_cmd)-1 ):
        procs.communicate()
        break
  del(ref_data_dic,ref_clim_dic,ref_cmd)

  #set a delay to ensure writing process done
  time.sleep(1)
  print("done submitting")

  #####################################################################
  # call mean_climate_driver.py to process diagnostics
  #####################################################################
  #defined regions
  regional = '{{ regional }}'
  if regional  == "y":
    default_regions = list('{{ regions }}'.split(","))
  else:
    default_regions = ["global", "NHEX", "SHEX", "TROPICS"]

  # create command list for mean climate driver
  lstcmd = []
  reg_var_dic = {}
  for vv in list("{{vars}}".split(",")):
    vkys = vv.split("-")[0]
    reg_var_dic[vkys] = default_regions
    vars = vv
    cmd0 = (" ".join(["mean_climate_driver.py",
                      "-p", "parameterfile.py",
		      "--vars", '{}'.format(vars)]))
    lstcmd.append(cmd0)
    del(cmd0,vars,vkys)

  #create regions for regional mean of each variable
  json.dump(reg_var_dic,
            open(os.path.join('${results_dir}','var_region_{{sub}}_catalogue.json'),"w"),
            sort_keys=True,
            indent=4,
            separators=(",", ": "))
  del(reg_var_dic)

  #finally process the data in parallel
  print("Number of jobs starting is ", str(len(lstcmd)))
  for i,p in enumerate(lstcmd):
    procs = subprocess.Popen([p], shell=True)
    print('running %s' % (str(p)))
    while (childCount() > {{num_workers}}):
      time.sleep(0.25)
      procs.communicate() # this will get the exit code
    else:
      if (i == len(lstcmd)-1 ):
        procs.communicate()
        break
  del(lstcmd,default_regions)

  #set a delay to avoid delay in writing process
  time.sleep(1)
  print("done submitting")

  # post process to reorgnize the metric data file
  variables = [s.split("/")[-1]
                for s in glob.glob(
                    os.path.join(
                        '${results_dir}',
                        "metrics_results",
                        "mean_climate",
  		  	 '{{mip}}',
                        '{{exp}}',
                        '${case_id}',
                        "*",
                    )
                )
                if os.path.isdir(s)
            ]

  #obs_sets = list('{{ reference_sets }}'.split(","))
  #for i, var in enumerate(variables):
  #  if len(obs_sets) != len(variables):
  #    obs = obs_sets[0]
  #  else:
  #    obs = obs_sets[i]
  #  merge_json('{{mip}}', '{{exp}}', '${case_id}', var, obs,
  #             test_start_yr, test_end_yr, '${results_dir}')

{%- endif %}

{%- if "variability_mode" in subset %}
  print("calculate mode variability metrics")
{%- if subset == "variability_mode_atm" %}
  modes = list({{ atm_modes }})
{% elif subset == "variability_mode_cpl" %}
  modes = list({{ cpl_modes }})
{%- endif %}

  lstcmd = []
  for variability_mode in modes:
    if variability_mode in ["NPO", "NPGO", "PSA1"]:
      eofn_obs = "2"
      eofn_mod = "2"
    elif variability_mode in ["PSA2"]:
      eofn_obs = "3"
      eofn_mod = "3"
    else:
      eofn_obs = "1"
      eofn_mod = "1"

    #####################################################################
    # call variability_modes_driver.py to process diagnostics
    #####################################################################
    cmd0 = (" ".join(['variability_modes_driver.py',
                      '-p', "parameterfile.py",
                      '--variability_mode', variability_mode,
                      '--eofn_mod', eofn_mod,
                      '--eofn_obs', eofn_obs ]))
    lstcmd.append(cmd0)
    del(cmd0)

  #finally process the data in parallel
  print("Number of jobs starting is ", str(len(lstcmd)))
  for i,p in enumerate(lstcmd):
    procs = subprocess.Popen([p], shell=True)
    print('running %s' % (str(p)))
    while (childCount() > {{num_workers}}):
      time.sleep(0.25)
      procs.communicate() # this will get the exit code
    else:
      if (i == len(lstcmd)-1 ):
        procs.communicate()
        break
  del(lstcmd)

  #set a delay to avoid delay in writing process
  time.sleep(1)
  print("done submitting")

{%- endif %}

{%- if "enso" in subset %}
  print("calculate enso metrics")
  groups = list({{ groups }})
  lstcmd = []
  for metricsCollection in groups:
    #####################################################################
    # call enso_driver.py to process diagnostics
    #####################################################################
    cmd0 = (" ".join(['enso_driver.py',
                      '-p', "parameterfile.py",
                      '--metricsCollection',metricsCollection]))
    lstcmd.append(cmd0)
    del(cmd0)

  #finally process the data in parallel
  print("Number of jobs starting is ", str(len(lstcmd)))
  for i,p in enumerate(lstcmd):
    procs = subprocess.Popen([p], shell=True)
    print('running %s' % (str(p)))
    while (childCount() > {{num_workers}}):
      time.sleep(0.25)
      procs.communicate() # this will get the exit code
    else:
      if (i == len(lstcmd)-1 ):
        procs.communicate()
        break
  del(lstcmd)

  #set a delay to avoid delay in writing process
  time.sleep(1)
  print("done submitting")

  #post process and generate figures
  #print("mip, exp, MC, case_id:", '{{ mip}}', '{{ exp }}', metricsCollection, '${case_id}')
  #merge_jsons('{{ mip }}', '{{ exp}}', '${case_id}', metricsCollection, '${results_dir}')

{%- endif %}

if __name__ == "__main__":
  main()

EOF

################################
# Run diagnostics
#command="srun -n 1 python -u pcmdi.py"
command="python -u pcmdi.py"
# Run diagnostics
time ${command}
if [ $? != 0 ]; then
  cd {{ scriptDir }}
  echo 'ERROR (10)' > {{ prefix }}.status
  exit 9
fi

# Copy output to web server
echo
echo ===== COPY FILES TO WEB SERVER =====
echo

# Create top-level directory
web_dir=${www}/${case}/pcmdi_diags #/{{ sub }}
mkdir -p ${web_dir}
if [ $? != 0 ]; then
  cd {{ scriptDir }}
  echo 'ERROR (10)' > {{ prefix }}.status
  exit 10
fi

{% if machine in ['pm-cpu', 'pm-gpu'] %}
# For NERSC, make sure it is world readable
f=`realpath ${web_dir}`
while [[ $f != "/" ]]
do
  owner=`stat --format '%U' $f`
  if [ "${owner}" = "${USER}" ]; then
    chgrp e3sm $f
    chmod go+rx $f
  fi
  f=$(dirname $f)
done
{% endif %}

# Copy files
#rsync -a --delete ${results_dir} ${web_dir}/
rsync -a ${results_dir} ${web_dir}/
if [ $? != 0 ]; then
  cd {{ scriptDir }}
  echo 'ERROR (11)' > {{ prefix }}.status
  exit 11
fi

{% if machine in ['pm-cpu', 'pm-gpu'] %}
# For NERSC, change permissions of new files
pushd ${web_dir}/
chgrp -R e3sm ${results_dir}
chmod -R go+rX,go-w ${results_dir}
popd
{% endif %}

{% if machine in ['anvil', 'chrysalis'] %}
# For LCRC, change permissions of new files
pushd ${web_dir}/
chmod -R go+rX,go-w ${results_dir}
popd
{% endif %}

# Delete temporary workdir
cd ..
if [[ "${debug,,}" != "true" ]]; then
  rm -rf ${workdir}
fi

# Update status file and exit
{% raw %}
ENDTIME=$(date +%s)
ELAPSEDTIME=$(($ENDTIME - $STARTTIME))
{% endraw %}
echo ==============================================
echo "Elapsed time: $ELAPSEDTIME seconds"
echo ==============================================
rm -f {{ prefix }}.status
echo 'OK' > {{ prefix }}.status
exit 0
